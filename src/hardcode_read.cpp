// This file is special in that it is included into the autogenerated file,
// and not compiled as a separate unit.

// TBD: move a lot of these into tracked objects instead
static VkInstance stored_instance = VK_NULL_HANDLE;
static VkPhysicalDevice selected_physical_device = VK_NULL_HANDLE;
static VkDebugReportCallbackEXT stored_callback = VK_NULL_HANDLE;
static bool callback_initialized = false;
static bool has_pipeline_feedback = false;
static bool has_pipeline_control = false;
static bool has_debug_report = false;
static bool has_debug_utils = false;
static int has_dedicated_allocation = 0;
static uint32_t selected_queue_family_index = 0xdeadbeef;
static VkPhysicalDeviceFeatures2 stored_VkPhysicalDeviceFeatures2 = { VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2, nullptr };
static VkPhysicalDeviceVulkan11Features stored_VkPhysicalDeviceVulkan11Features = {};
static VkPhysicalDeviceVulkan12Features stored_VkPhysicalDeviceVulkan12Features = {};
static VkPhysicalDeviceVulkan13Features stored_VkPhysicalDeviceVulkan13Features = {};
static std::vector<VkQueueFamilyProperties> device_VkQueueFamilyProperties;
static bool has_VkPhysicalDeviceFeatures2 = false;
static bool has_VkPhysicalDeviceVulkan11Features = false;
static bool has_VkPhysicalDeviceVulkan12Features = false;
static bool has_VkPhysicalDeviceVulkan13Features = false;
static bool host_has_frame_boundary = false;

static void memory_report_callback(
	const VkDeviceMemoryReportCallbackDataEXT*  pCallbackData,
	void*                                       pUserData)
{
	// TBD
}

static VkBool32 VKAPI_PTR messenger_callback(
	VkDebugUtilsMessageSeverityFlagBitsEXT           messageSeverity,
	VkDebugUtilsMessageTypeFlagsEXT                  messageTypes,
	const VkDebugUtilsMessengerCallbackDataEXT*      pCallbackData,
	void*                                            pUserData)
{
	if (!is_debug() && (messageSeverity == VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT || messageSeverity == VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT)) return VK_TRUE;
	ILOG("messenger (s%d, t%d): %s", (int)messageSeverity, (int)messageTypes, pCallbackData->pMessage);
	return VK_TRUE;
}

static VkBool32 VKAPI_PTR debug_report_callback(
	VkDebugReportFlagsEXT                       flags,
	VkDebugReportObjectTypeEXT                  objectType,
	uint64_t                                    object,
	size_t                                      location,
	int32_t                                     messageCode,
	const char*                                 pLayerPrefix,
	const char*                                 pMessage,
	void*                                       pUserData)
{
	if (((flags & VK_DEBUG_REPORT_INFORMATION_BIT_EXT) || (flags & VK_DEBUG_REPORT_DEBUG_BIT_EXT)) && !is_debug()) return VK_TRUE;
	ILOG("%s (%d): %s", pLayerPrefix, messageCode, pMessage);
	return VK_TRUE;
}

static uint64_t debug_object_lookup(VkDebugReportObjectTypeEXT type, uint32_t index)
{
	switch (type)
	{
	case VK_DEBUG_REPORT_OBJECT_TYPE_INSTANCE_EXT: return (uint64_t)stored_instance;
	case VK_DEBUG_REPORT_OBJECT_TYPE_PHYSICAL_DEVICE_EXT: return (uint64_t)selected_physical_device;
	case VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT: return (uint64_t)index_to_VkDevice.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_QUEUE_EXT: return (uint64_t)index_to_VkQueue.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_MEMORY_EXT: return 0;
	case VK_DEBUG_REPORT_OBJECT_TYPE_SEMAPHORE_EXT: return (uint64_t)index_to_VkSemaphore.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_BUFFER_EXT: return (uint64_t)index_to_VkCommandBuffer.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_FENCE_EXT: return (uint64_t)index_to_VkFence.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_EXT: return (uint64_t)index_to_VkBuffer.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_EXT: return (uint64_t)index_to_VkImage.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_EVENT_EXT: return (uint64_t)index_to_VkEvent.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_QUERY_POOL_EXT: return (uint64_t)index_to_VkQueryPool.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_VIEW_EXT: return (uint64_t)index_to_VkBufferView.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_VIEW_EXT: return (uint64_t)index_to_VkImageView.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT: return (uint64_t)index_to_VkShaderModule.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_CACHE_EXT: return (uint64_t)index_to_VkPipelineCache.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_LAYOUT_EXT: return (uint64_t)index_to_VkPipelineLayout.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_RENDER_PASS_EXT: return (uint64_t)index_to_VkRenderPass.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_EXT: return (uint64_t)index_to_VkPipeline.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT_EXT: return (uint64_t)index_to_VkDescriptorSetLayout.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_EXT: return (uint64_t)index_to_VkSampler.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_POOL_EXT: return (uint64_t)index_to_VkDescriptorPool.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_EXT: return (uint64_t)index_to_VkDescriptorSet.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_FRAMEBUFFER_EXT: return (uint64_t)index_to_VkFramebuffer.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_POOL_EXT: return (uint64_t)index_to_VkCommandPool.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_SURFACE_KHR_EXT: return (uint64_t)index_to_VkSurfaceKHR.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_SWAPCHAIN_KHR_EXT: return (uint64_t)index_to_VkSwapchainKHR.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_EXT: return (uint64_t)index_to_VkDescriptorUpdateTemplate.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_KHR_EXT: return (uint64_t)index_to_VkDisplayKHR.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_MODE_KHR_EXT: return (uint64_t)index_to_VkDisplayModeKHR.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_KHR_EXT: return (uint64_t)index_to_VkAccelerationStructureKHR.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT: return (uint64_t)index_to_VkValidationCacheEXT.at(index);
	case VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR_EXT: return (uint64_t)index_to_VkSamplerYcbcrConversion.at(index);
	// these are not supported:
	case VK_DEBUG_REPORT_OBJECT_TYPE_CUDA_MODULE_NV_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_CUDA_FUNCTION_NV_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_CU_MODULE_NVX_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_CU_FUNCTION_NVX_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_COLLECTION_FUCHSIA_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_UNKNOWN_EXT:
	case VK_DEBUG_REPORT_OBJECT_TYPE_MAX_ENUM_EXT: assert(false); return 0;
	}
	return 0;
}

static uint64_t object_lookup(VkObjectType type, uint32_t index)
{
	switch (type)
	{
	case VK_OBJECT_TYPE_INSTANCE: return (uint64_t)stored_instance;
	case VK_OBJECT_TYPE_PHYSICAL_DEVICE: return (uint64_t)selected_physical_device;
	case VK_OBJECT_TYPE_DEVICE: return (uint64_t)index_to_VkDevice.at(index);
	case VK_OBJECT_TYPE_QUEUE: return (uint64_t)index_to_VkQueue.at(index);
	case VK_OBJECT_TYPE_DEVICE_MEMORY: return 0;
	case VK_OBJECT_TYPE_SEMAPHORE: return (uint64_t)index_to_VkSemaphore.at(index);
	case VK_OBJECT_TYPE_COMMAND_BUFFER: return (uint64_t)index_to_VkCommandBuffer.at(index);
	case VK_OBJECT_TYPE_FENCE: return (uint64_t)index_to_VkFence.at(index);
	case VK_OBJECT_TYPE_BUFFER: return (uint64_t)index_to_VkBuffer.at(index);
	case VK_OBJECT_TYPE_IMAGE: return (uint64_t)index_to_VkImage.at(index);
	case VK_OBJECT_TYPE_EVENT: return (uint64_t)index_to_VkEvent.at(index);
	case VK_OBJECT_TYPE_QUERY_POOL: return (uint64_t)index_to_VkQueryPool.at(index);
	case VK_OBJECT_TYPE_BUFFER_VIEW: return (uint64_t)index_to_VkBufferView.at(index);
	case VK_OBJECT_TYPE_IMAGE_VIEW: return (uint64_t)index_to_VkImageView.at(index);
	case VK_OBJECT_TYPE_SHADER_MODULE: return (uint64_t)index_to_VkShaderModule.at(index);
	case VK_OBJECT_TYPE_PIPELINE_CACHE: return (uint64_t)index_to_VkPipelineCache.at(index);
	case VK_OBJECT_TYPE_PIPELINE_LAYOUT: return (uint64_t)index_to_VkPipelineLayout.at(index);
	case VK_OBJECT_TYPE_RENDER_PASS: return (uint64_t)index_to_VkRenderPass.at(index);
	case VK_OBJECT_TYPE_PIPELINE: return (uint64_t)index_to_VkPipeline.at(index);
	case VK_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT: return (uint64_t)index_to_VkDescriptorSetLayout.at(index);
	case VK_OBJECT_TYPE_SAMPLER: return (uint64_t)index_to_VkSampler.at(index);
	case VK_OBJECT_TYPE_DESCRIPTOR_POOL: return (uint64_t)index_to_VkDescriptorPool.at(index);
	case VK_OBJECT_TYPE_DESCRIPTOR_SET: return (uint64_t)index_to_VkDescriptorSet.at(index);
	case VK_OBJECT_TYPE_FRAMEBUFFER: return (uint64_t)index_to_VkFramebuffer.at(index);
	case VK_OBJECT_TYPE_COMMAND_POOL: return (uint64_t)index_to_VkCommandPool.at(index);
	case VK_OBJECT_TYPE_SURFACE_KHR: return (uint64_t)index_to_VkSurfaceKHR.at(index);
	case VK_OBJECT_TYPE_SWAPCHAIN_KHR: return (uint64_t)index_to_VkSwapchainKHR.at(index);
	case VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE: return (uint64_t)index_to_VkDescriptorUpdateTemplate.at(index);
	case VK_OBJECT_TYPE_DISPLAY_KHR: return (uint64_t)index_to_VkDisplayKHR.at(index);
	case VK_OBJECT_TYPE_DISPLAY_MODE_KHR: return (uint64_t)index_to_VkDisplayModeKHR.at(index);
	case VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_KHR: return (uint64_t)index_to_VkAccelerationStructureKHR.at(index);
	case VK_OBJECT_TYPE_VALIDATION_CACHE_EXT: return (uint64_t)index_to_VkValidationCacheEXT.at(index);
	case VK_OBJECT_TYPE_DEFERRED_OPERATION_KHR: return (uint64_t)index_to_VkDeferredOperationKHR.at(index);
	case VK_OBJECT_TYPE_MICROMAP_EXT: return (uint64_t)index_to_VkMicromapEXT.at(index);
	case VK_OBJECT_TYPE_PRIVATE_DATA_SLOT: return (uint64_t)index_to_VkPrivateDataSlot.at(index);
	case VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR: return (uint64_t)index_to_VkSamplerYcbcrConversion.at(index);
	case VK_OBJECT_TYPE_VIDEO_SESSION_KHR: return (uint64_t)index_to_VkVideoSessionKHR.at(index);
	case VK_OBJECT_TYPE_VIDEO_SESSION_PARAMETERS_KHR: return (uint64_t)index_to_VkVideoSessionParametersKHR.at(index);
	case VK_OBJECT_TYPE_SHADER_EXT: return (uint64_t)index_to_VkShaderEXT.at(index);
	case VK_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT: return (uint64_t)index_to_VkDebugReportCallbackEXT.at(index);
	case VK_OBJECT_TYPE_DEBUG_UTILS_MESSENGER_EXT: return (uint64_t)index_to_VkDebugUtilsMessengerEXT.at(index);
	// these are not supported:
	case VK_OBJECT_TYPE_CUDA_MODULE_NV:
	case VK_OBJECT_TYPE_CUDA_FUNCTION_NV:
	case VK_OBJECT_TYPE_OPTICAL_FLOW_SESSION_NV:
	case VK_OBJECT_TYPE_BUFFER_COLLECTION_FUCHSIA:
	case VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NV:
	case VK_OBJECT_TYPE_PERFORMANCE_CONFIGURATION_INTEL:
	case VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV:
	case VK_OBJECT_TYPE_CU_FUNCTION_NVX:
	case VK_OBJECT_TYPE_CU_MODULE_NVX:
	case VK_OBJECT_TYPE_PIPELINE_BINARY_KHR:
	case VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_EXT:
	case VK_OBJECT_TYPE_INDIRECT_EXECUTION_SET_EXT:
	case VK_OBJECT_TYPE_UNKNOWN:
	case VK_OBJECT_TYPE_MAX_ENUM: assert(false); return 0;
	}
	return 0;
}

void replay_pre_vkQueueSubmit2(lava_file_reader& reader, VkQueue queue, uint32_t submitCount, const VkSubmitInfo2* pSubmits, VkFence fence)
{
	for (uint32_t i = 0; i < submitCount; i++)
	{
		if (!host_has_frame_boundary) purge_extension_parent(const_cast<VkSubmitInfo2*>(&pSubmits[i]), VK_STRUCTURE_TYPE_FRAME_BOUNDARY_EXT);
	}
}

void replay_pre_vkQueueSubmit2KHR(lava_file_reader& reader, VkQueue queue, uint32_t submitCount, const VkSubmitInfo2KHR* pSubmits, VkFence fence)
{
	replay_pre_vkQueueSubmit2(reader, queue, submitCount, pSubmits, fence);
}

void replay_pre_vkQueueSubmit(lava_file_reader& reader, VkQueue queue, uint32_t submitCount, const VkSubmitInfo* pSubmits, VkFence fence)
{
	for (uint32_t i = 0; i < submitCount; i++)
	{
		if (!host_has_frame_boundary) purge_extension_parent(const_cast<VkSubmitInfo*>(&pSubmits[i]), VK_STRUCTURE_TYPE_FRAME_BOUNDARY_EXT);
	}
}

void replay_pre_vkCreateSampler(lava_file_reader& reader, VkDevice device, VkSamplerCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSampler* pSampler)
{
	if (no_anisotropy())
	{
		pCreateInfo->anisotropyEnable = VK_FALSE;
	}
}

void replay_pre_vkCreatePipelineCache(lava_file_reader& reader, VkDevice device, uint32_t device_index, VkPipelineCacheCreateInfo* pCreateInfo, uint32_t cache_index)
{
	if (pCreateInfo->initialDataSize > 0)
	{
		ABORT("vkCreatePipelineCache %u already has a pipeline cache! This should never happen!", cache_index);
	}
	const char* load = load_pipelinecache();
	if (load)
	{
		std::string filename = std::string(load) + "/" + _to_string(cache_index) + ".cache";
		FILE* fp = fopen(filename.c_str(), "r");
		if (fp)
		{
			struct stat st;
			fstat(fileno(fp), &st);
			char* ptr = reader.pool.allocate<char>(st.st_size);
			size_t size = fread(ptr, st.st_size, 1, fp);
			if (size != 1) ELOG("Failed to read pipeline cache from %s: %s", filename.c_str(), strerror(errno));
			fclose(fp);
			pCreateInfo->pInitialData = ptr;
			pCreateInfo->initialDataSize = st.st_size;
			ILOG("Using pipeline cache %u from %s", cache_index, filename.c_str());
		}
		else
		{
			ELOG("Failed to open pipeline cache file %s: %s", filename.c_str(), strerror(errno));
		}
	}
}

void replay_pre_vkDestroyPipelineCache(lava_file_reader& reader, VkDevice device, VkPipelineCache pipelineCache, const VkAllocationCallbacks* pAllocator)
{
	const uint32_t device_index = index_to_VkDevice.index(device);
	const uint32_t cache_index = index_to_VkPipelineCache.index(pipelineCache);
	const char* savedir = save_pipelinecache();
	if (savedir && pipelineCache != VK_NULL_HANDLE)
	{
		mkdir(savedir, 0777); // just in case
		size_t dataSize = 0;
		wrap_vkGetPipelineCacheData(device, pipelineCache, &dataSize, nullptr);
		if (dataSize > 0)
		{
			std::vector<char> data(dataSize);
			wrap_vkGetPipelineCacheData(device, pipelineCache, &dataSize, data.data());
			std::string filename = std::string(savedir) + "/" + _to_string(cache_index) + ".cache";
			FILE* fp = fopen(filename.c_str(), "w");
			if (fp)
			{
				size_t written = fwrite(data.data(), data.size(), 1, fp);
				if (written != 1) ELOG("Failed to write pipeline cache to %s: %s", filename.c_str(), strerror(errno));
				fclose(fp);
			}
			else
			{
				ELOG("Failed to open pipeline cache file %s: %s", filename.c_str(), strerror(errno));
			}
		}
		else
		{
			ELOG("Wanted to save it, but pipeline cache %u is empty!", cache_index);
		}
	}
}

void retrace_vkDestroySurfaceKHR(lava_file_reader& reader)
{
	// Declarations
	VkSurfaceKHR surface;
	// Load
	const uint32_t instance_index = reader.read_handle();
	VkInstance instance = index_to_VkInstance.at(instance_index);
	const uint8_t surface_opt = reader.read_uint8_t(); // whether we should load this optional value
	uint32_t surface_index = 0;
	if (surface_opt)
	{
		surface_index = reader.read_handle();
		surface = index_to_VkSurfaceKHR.at(surface_index);
		if (!is_noscreen() && reader.run)
		{
			VkAllocationCallbacks allocator = {};
			VkAllocationCallbacks* pAllocator = &allocator;
			allocators_set(pAllocator);
			wrap_vkDestroySurfaceKHR(instance, surface, pAllocator);
			window_destroy(instance, surface_index);
		}
		index_to_VkSurfaceKHR.unset(surface_index);
	}
}

static void replay_pre_vkDestroySwapchainKHR(lava_file_reader& reader, VkDevice device, VkSwapchainKHR swapchain, const VkAllocationCallbacks* pAllocator)
{
	trackedswapchain_replay& t = VkSwapchainKHR_index.at(index_to_VkSwapchainKHR.index(swapchain));
	assert(device == t.device);
	for (unsigned i = 0; i < t.virtual_fences.size(); i++)
	{
		if (!t.inflight.at(i)) continue;
		// check status, wait if needed, then delete
		VkResult r = wrap_vkGetFenceStatus(device, t.virtual_fences.at(i));
		if (r == VK_NOT_READY)
		{
			r = wrap_vkWaitForFences(device, 1, &t.virtual_fences.at(i), VK_TRUE, UINT64_MAX);
		}
		wrap_vkDestroyFence(device, t.virtual_fences.at(i), nullptr);
		wrap_vkDestroyImage(device, t.virtual_images.at(i), nullptr);
	}
	if (t.virtual_cmdpool != VK_NULL_HANDLE) wrap_vkResetCommandPool(device, t.virtual_cmdpool, VK_COMMAND_POOL_RESET_RELEASE_RESOURCES_BIT);
	if (t.virtual_cmdpool != VK_NULL_HANDLE) wrap_vkFreeCommandBuffers(device, t.virtual_cmdpool, t.virtual_cmdbuffers.size(), t.virtual_cmdbuffers.data());
	wrap_vkDestroyCommandPool(device, t.virtual_cmdpool, nullptr);
	wrap_vkDestroySemaphore(device, t.virtual_semaphore, nullptr);
}

static void replay_post_vkGetAccelerationStructureDeviceAddressKHR(lava_file_reader& reader, VkDeviceAddress result, VkDevice device, const VkAccelerationStructureDeviceAddressInfoKHR* pInfo)
{
	const uint32_t as_index = index_to_VkAccelerationStructureKHR.index(pInfo->accelerationStructure);
	VkAccelerationStructureKHR_index.at(as_index).device_address = result;
}

static void replay_post_vkGetBufferDeviceAddressKHR(lava_file_reader& reader, VkDeviceAddress result, VkDevice device, const VkBufferDeviceAddressInfoKHR* pInfo)
{
	const uint32_t buffer_index = index_to_VkBuffer.index(pInfo->buffer);
	VkBuffer_index.at(buffer_index).device_address = result;
}

static void replay_post_vkGetBufferDeviceAddress(lava_file_reader& reader, VkDeviceAddress result, VkDevice device, const VkBufferDeviceAddressInfo* pInfo)
{
	const uint32_t buffer_index = index_to_VkBuffer.index(pInfo->buffer);
	VkBuffer_index.at(buffer_index).device_address = result;
}

void replay_post_vkAcquireNextImageKHR(lava_file_reader& reader, VkResult result, VkDevice device, VkSwapchainKHR swapchain, uint64_t timeout,
                                     VkSemaphore semaphore, VkFence fence, uint32_t* pImageIndex)
{
	if (result == VK_INCOMPLETE) return; // means we skipped it
	const uint32_t swapchainkhr_index = index_to_VkSwapchainKHR.index(swapchain);
	const uint32_t next_image = VkSwapchainKHR_index.at(swapchainkhr_index).next_swapchain_image;
	DLOG("Acquired next swapchain image index=%u (stored next image was %u), returned %s", next_image, *pImageIndex, errorString(result));
	assert(is_virtualswapchain() || next_image == *pImageIndex);
}

void replay_post_vkAcquireNextImage2KHR(lava_file_reader& reader, VkResult result, VkDevice device, const VkAcquireNextImageInfoKHR* pAcquireInfo, uint32_t* pImageIndex)
{
	if (result == VK_INCOMPLETE) return; // means we skipped it
	const uint32_t swapchainkhr_index = index_to_VkSwapchainKHR.index(pAcquireInfo->swapchain);
	const uint32_t next_image = VkSwapchainKHR_index.at(swapchainkhr_index).next_swapchain_image;
	DLOG("Acquired next swapchain image index=%u (stored next image was %u), returned %s", next_image, *pImageIndex, errorString(result));
	assert(is_virtualswapchain() || next_image == *pImageIndex);
}

// make or remake swapchain images
static VkSwapchainKHR remake_swapchain(lava_file_reader& reader, VkQueue queue, VkSwapchainKHR old_swapchain, trackedswapchain_replay* data)
{
	assert(reader.run);
	// TBD check surface capabilities, these values may not be supported
	VkSwapchainCreateInfoKHR s = { VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR, nullptr };
	s.flags = data->info.flags;
	s.surface = data->info.surface;
	if (p__realimages > 0) s.minImageCount = p__realimages;
	else s.minImageCount = data->info.minImageCount;
	s.imageFormat = data->info.imageFormat;
	s.imageColorSpace = data->info.imageColorSpace;
	s.imageExtent = data->info.imageExtent;
	s.imageArrayLayers = data->info.imageArrayLayers;
	s.imageUsage = data->info.imageUsage;
	s.imageSharingMode = data->info.imageSharingMode;
	s.queueFamilyIndexCount = 0;
	s.pQueueFamilyIndices = nullptr;
	s.preTransform = data->info.preTransform;
	s.compositeAlpha = data->info.compositeAlpha;
	s.presentMode = data->info.presentMode;
	s.clipped = data->info.clipped;
	s.oldSwapchain = old_swapchain;
	// make new one
	VkSwapchainKHR swapchain;
	VkResult r = wrap_vkCreateSwapchainKHR(data->device, &s, nullptr, &swapchain);
	assert(r == VK_SUCCESS);
	// delete old one
	const uint32_t old_swapchainkhr_index = index_to_VkSwapchainKHR.index(old_swapchain);
	wrap_vkDestroySwapchainKHR(data->device, old_swapchain, nullptr);
	// replace old->new
	index_to_VkSwapchainKHR.replace(old_swapchainkhr_index, swapchain);
	// replace swapchain images
	uint32_t swapchainImageCount = 0;
	r = wrap_vkGetSwapchainImagesKHR(data->device, swapchain, &swapchainImageCount, nullptr);
	data->pSwapchainImages.resize(swapchainImageCount);
	r = wrap_vkGetSwapchainImagesKHR(data->device, swapchain, &swapchainImageCount, data->pSwapchainImages.data());
	assert(r == VK_SUCCESS);
	(void)r;
	return swapchain;
}

void replay_pre_vkQueuePresentKHR(lava_file_reader& reader, VkQueue queue, VkPresentInfoKHR* pPresentInfo)
{
	if (pPresentInfo->pResults == nullptr) // we always want this info back
	{
		pPresentInfo->pResults = reader.pool.allocate<VkResult>(pPresentInfo->swapchainCount);
	}
	if (is_virtualswapchain())
	{
		VkResult result;
		VkSemaphore* semaphores = reader.pool.allocate<VkSemaphore>(pPresentInfo->waitSemaphoreCount + pPresentInfo->swapchainCount);
		for (uint32_t i = 0; i < pPresentInfo->waitSemaphoreCount; i++) semaphores[i] = pPresentInfo->pWaitSemaphores[i];
		for (uint32_t i = 0; i < pPresentInfo->swapchainCount; i++)
		{
			const uint32_t swapchainkhr_index = index_to_VkSwapchainKHR.index(pPresentInfo->pSwapchains[i]);
			auto& data = VkSwapchainKHR_index.at(swapchainkhr_index);
			// check that commandbuffer is actually available (this SHOULD be a noop!)
			if (data.inflight.at(data.next_stored_image))
			{
				result = wrap_vkWaitForFences(data.device, 1, &data.virtual_fences[data.next_stored_image], VK_TRUE, 0);
				if (result != VK_SUCCESS)
				{
					ELOG("Fence was not ready for commandbuffer %u", data.next_stored_image);
					result = wrap_vkWaitForFences(data.device, 1, &data.virtual_fences[data.next_stored_image], VK_TRUE, UINT64_MAX);
					assert(result == VK_SUCCESS);
				}
				result = wrap_vkResetFences(data.device, 1, &data.virtual_fences[data.next_stored_image]);
				assert(result == VK_SUCCESS);
			}
			data.inflight[data.next_stored_image] = true; // now using it, if we weren't already
			// copy virtual -> real
			semaphores[pPresentInfo->waitSemaphoreCount + i] = data.virtual_semaphore;
			VkCommandBufferBeginInfo command_buffer_begin_info = {};
			command_buffer_begin_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
			result = wrap_vkBeginCommandBuffer(data.virtual_cmdbuffers[data.next_stored_image], &command_buffer_begin_info);
			assert(result == VK_SUCCESS);
			std::vector<VkImageMemoryBarrier> image_barriers(2);
			VkImageMemoryBarrier& image_barrier_src = image_barriers.at(0);
			VkImageMemoryBarrier& image_barrier_dst = image_barriers.at(1);
			image_barrier_src.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
			image_barrier_src.pNext = nullptr;
			image_barrier_dst.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
			image_barrier_dst.pNext = nullptr;
			image_barrier_src.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			image_barrier_src.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
			image_barrier_dst.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			image_barrier_dst.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
			image_barrier_src.oldLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR; // TBD could also be VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR
			image_barrier_src.newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			image_barrier_dst.oldLayout = VK_IMAGE_LAYOUT_UNDEFINED;
			image_barrier_dst.newLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
			image_barrier_src.srcQueueFamilyIndex = selected_queue_family_index;
			image_barrier_src.dstQueueFamilyIndex = selected_queue_family_index;
			image_barrier_dst.srcQueueFamilyIndex = selected_queue_family_index;
			image_barrier_dst.dstQueueFamilyIndex = selected_queue_family_index;
			image_barrier_src.image = data.virtual_images[data.next_stored_image];
			image_barrier_dst.image = data.pSwapchainImages[data.next_swapchain_image];
			image_barrier_src.subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, VK_REMAINING_MIP_LEVELS, 0, VK_REMAINING_ARRAY_LAYERS };
			image_barrier_dst.subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, VK_REMAINING_MIP_LEVELS, 0, VK_REMAINING_ARRAY_LAYERS };
			wrap_vkCmdPipelineBarrier(data.virtual_cmdbuffers[data.next_stored_image], VK_PIPELINE_STAGE_TRANSFER_BIT,
				VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT, 0, 0, NULL, 0, NULL, image_barriers.size(), image_barriers.data());
			if (!p__virtualperfmode) // actually do the copy if not in performance mode
			{
				VkMemoryBarrier memory_barrier = {};
				memory_barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER;
				memory_barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
				memory_barrier.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
				wrap_vkCmdCopyImage(data.virtual_cmdbuffers[data.next_stored_image], data.virtual_images[data.next_stored_image], VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
					data.pSwapchainImages[data.next_swapchain_image], VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &data.virtual_image_copy_region);
			}
			image_barrier_dst.srcAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
			image_barrier_src.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			image_barrier_src.newLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR; // TBD could also be VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR
			image_barrier_dst.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
			image_barrier_dst.newLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR; // TBD could also be VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR
			wrap_vkCmdPipelineBarrier(data.virtual_cmdbuffers[data.next_stored_image], VK_PIPELINE_STAGE_TRANSFER_BIT,
				VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT, 0, 0, NULL, 0, NULL, image_barriers.size(), image_barriers.data());
			result = wrap_vkEndCommandBuffer(data.virtual_cmdbuffers[data.next_stored_image]);
			assert(result == VK_SUCCESS);
			DLOG("Presenting with virtual swapchain image index %u(0x%lx) instead of real swapchain image %u(0x%lx) on swapchain %lx", data.next_swapchain_image,
				(unsigned long)data.virtual_images[data.next_stored_image], pPresentInfo->pImageIndices[i], (unsigned long)data.pSwapchainImages[data.next_swapchain_image],
				(unsigned long)pPresentInfo->pSwapchains[i]);
			// replace with virtual swapchain image
			const_cast<uint32_t*>(pPresentInfo->pImageIndices)[i] = data.next_swapchain_image;

			VkSubmitInfo submit = {};
			submit.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
			submit.commandBufferCount = 1;
			submit.pCommandBuffers = &data.virtual_cmdbuffers[data.next_stored_image];
			submit.signalSemaphoreCount = 1;
			submit.pSignalSemaphores = &data.virtual_semaphore;
			result = wrap_vkQueueSubmit(queue, 1, &submit, data.virtual_fences[data.next_stored_image]);
			assert(result == VK_SUCCESS);
		}
		pPresentInfo->waitSemaphoreCount = pPresentInfo->waitSemaphoreCount + pPresentInfo->swapchainCount;
		pPresentInfo->pWaitSemaphores = semaphores;
	}
	else
	{
		for (uint32_t i = 0; i < pPresentInfo->swapchainCount; i++)
		{
			DLOG("Presenting with swapchain image index %u on swapchain id %lu", pPresentInfo->pImageIndices[i], (unsigned long)pPresentInfo->pSwapchains[i]);
		}
	}
}

static void cleanup_sync(VkQueue queue, uint32_t waitSemaphoreCount, const VkSemaphore *waitSemaphores, uint32_t signalSemaphoreCount, const VkSemaphore *signalSemaphores, VkFence fence)
{
	const VkPipelineStageFlags flags = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT;
	VkSubmitInfo submit_info = { VK_STRUCTURE_TYPE_SUBMIT_INFO, nullptr, waitSemaphoreCount, waitSemaphores, &flags, 0, nullptr, signalSemaphoreCount, signalSemaphores };
	VkResult result = wrap_vkQueueSubmit(queue, 1, &submit_info, fence);
	assert(result == VK_SUCCESS);
}

void replay_post_vkQueuePresentKHR(lava_file_reader& reader, VkResult result, VkQueue queue, VkPresentInfoKHR* pPresentInfo)
{
	if (is_virtualswapchain() && (result == VK_SUBOPTIMAL_KHR || result == VK_ERROR_OUT_OF_DATE_KHR))
	{
		ILOG("We got %s from vkQueuePresentKHR -- remaking the swapchain!", errorString(result));

		// first, reset our semaphores
		cleanup_sync(queue, pPresentInfo->waitSemaphoreCount, pPresentInfo->pWaitSemaphores, 0, nullptr, VK_NULL_HANDLE);
		pPresentInfo->waitSemaphoreCount--; // remove the one we added

		// second, redo the affected swapchain(s)
		VkSwapchainKHR* pSwapchains = reader.pool.allocate<VkSwapchainKHR>(pPresentInfo->swapchainCount);
		uint32_t swapchainCount = 0;
		uint32_t* pImageIndices = reader.pool.allocate<uint32_t>(pPresentInfo->swapchainCount);
		for (uint32_t i = 0; i < pPresentInfo->swapchainCount; i++)
		{
			if (pPresentInfo->pResults[i] != VK_SUCCESS)
			{
				const uint32_t swapchainkhr_index = index_to_VkSwapchainKHR.index(pPresentInfo->pSwapchains[i]);
				auto& data = VkSwapchainKHR_index.at(swapchainkhr_index);
				pSwapchains[swapchainCount] = remake_swapchain(reader, queue, pPresentInfo->pSwapchains[i], &data);
				pImageIndices[swapchainCount] = pPresentInfo->pImageIndices[i];
				swapchainCount++;
			}
		}
		pPresentInfo->pSwapchains = pSwapchains;
		pPresentInfo->swapchainCount = swapchainCount;
		pPresentInfo->pImageIndices = pImageIndices;

		// third, reissue call using only the failed swapchains
		assert(swapchainCount > 0);
		replay_pre_vkQueuePresentKHR(reader, queue, pPresentInfo);
		result = wrap_vkQueuePresentKHR(queue, pPresentInfo);
		assert(result == VK_SUCCESS);
	}
	else if (!is_virtualswapchain()) assert(result == VK_SUCCESS || result == VK_SUBOPTIMAL_KHR);
}

void replay_pre_vkCreateSharedSwapchainsKHR(lava_file_reader& reader, VkDevice device, uint32_t swapchainCount, VkSwapchainCreateInfoKHR* pCreateInfos, VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchains)
{
	if (is_virtualswapchain())
	{
		for (uint32_t i = 0; i < swapchainCount; i++)
		{
			if (p__realpresentmode != VK_PRESENT_MODE_MAX_ENUM_KHR) pCreateInfos[i].presentMode = p__realpresentmode;
			if (p__realimages > 0) pCreateInfos[i].minImageCount = p__realimages;
			pCreateInfos[i].imageUsage |= VK_IMAGE_USAGE_TRANSFER_DST_BIT; // make sure it has this
		}
	}
}

void replay_pre_vkCreateSwapchainKHR(lava_file_reader& reader, VkDevice device, VkSwapchainCreateInfoKHR* pCreateInfo, VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchain)
{
	if (is_virtualswapchain())
	{
		if (p__realpresentmode != VK_PRESENT_MODE_MAX_ENUM_KHR) pCreateInfo->presentMode = p__realpresentmode;
		if (p__realimages > 0) pCreateInfo->minImageCount = p__realimages;
		pCreateInfo->imageUsage |= VK_IMAGE_USAGE_TRANSFER_DST_BIT; // make sure it has this
	}
}

void replay_pre_vkCreateDevice(lava_file_reader& reader, VkPhysicalDevice physicalDevice, VkDeviceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDevice* pDevice)
{
	pCreateInfo->enabledLayerCount = 0; // even though implementation should ignore it as per the spec, that is not always the case, so help it along

	// Limit the number of requested queues to what is available
	VkDeviceQueueCreateInfo* queueinfo = reader.pool.allocate<VkDeviceQueueCreateInfo>(pCreateInfo->queueCreateInfoCount);
	for (uint32_t i = 0; i < pCreateInfo->queueCreateInfoCount; i++)
	{
		queueinfo[i] = pCreateInfo->pQueueCreateInfos[i]; // struct copy
		if (queueinfo[i].queueFamilyIndex == selected_queue_family_index
		    && queueinfo[i].queueCount > device_VkQueueFamilyProperties.at(selected_queue_family_index).queueCount)
		{
			queueinfo[i].queueCount = device_VkQueueFamilyProperties.at(selected_queue_family_index).queueCount;
		}
	}
	pCreateInfo->pQueueCreateInfos = queueinfo;

	// Replace stored features with a pruned feature list
	VkBaseOutStructure *ext = (VkBaseOutStructure*)find_extension_parent(pCreateInfo, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_1_FEATURES);
	if (ext && has_VkPhysicalDeviceVulkan11Features)
	{
		stored_VkPhysicalDeviceVulkan11Features.pNext = ext->pNext->pNext;
		ext->pNext = (VkBaseOutStructure*)&stored_VkPhysicalDeviceVulkan11Features;
	}
	ext = (VkBaseOutStructure*)find_extension_parent(pCreateInfo, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_2_FEATURES);
	if (ext && has_VkPhysicalDeviceVulkan12Features)
	{
		stored_VkPhysicalDeviceVulkan12Features.pNext = ext->pNext->pNext;
		ext->pNext = (VkBaseOutStructure*)&stored_VkPhysicalDeviceVulkan12Features;
	}
	ext = (VkBaseOutStructure*)find_extension_parent(pCreateInfo, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_3_FEATURES);
	if (ext && has_VkPhysicalDeviceVulkan13Features)
	{
		stored_VkPhysicalDeviceVulkan13Features.pNext = ext->pNext->pNext;
		ext->pNext = (VkBaseOutStructure*)&stored_VkPhysicalDeviceVulkan13Features;
	}
	ext = (VkBaseOutStructure*)find_extension_parent(pCreateInfo, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2);
	if (ext && has_VkPhysicalDeviceFeatures2)
	{
		stored_VkPhysicalDeviceFeatures2.pNext = ext->pNext->pNext;
		ext->pNext = (VkBaseOutStructure*)&stored_VkPhysicalDeviceFeatures2;
		pCreateInfo->pEnabledFeatures = nullptr;
	}
	else if (has_VkPhysicalDeviceFeatures2) // use the old way, just stored in the new way
	{
		pCreateInfo->pEnabledFeatures = &stored_VkPhysicalDeviceFeatures2.features; // struct copy
	}

	// TBD replace feature extensions

	if (no_anisotropy())
	{
		static VkPhysicalDeviceFeatures backup_features = *pCreateInfo->pEnabledFeatures; // struct copy
		backup_features.samplerAnisotropy = VK_FALSE;
		pCreateInfo->pEnabledFeatures = &backup_features;
	}
}

void replay_post_vkCreateInstance(lava_file_reader& reader, VkResult result, const VkInstanceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkInstance* pInstance)
{
	if (!pInstance || !*pInstance || *pInstance == VK_NULL_HANDLE)
	{
		ABORT("Failed to create a Vulkan instance: %s", errorString(result));
	}
	stored_instance = *pInstance;

	// Find the physical device we want to create, and point all physical device references to it
	uint32_t num_phys_devices = 0;
	result = wrap_vkEnumeratePhysicalDevices(*pInstance, &num_phys_devices, nullptr);
	assert(result == VK_SUCCESS);
	std::vector<VkPhysicalDevice> physical_devices(num_phys_devices);
	result = wrap_vkEnumeratePhysicalDevices(*pInstance, &num_phys_devices, physical_devices.data());
	assert(result == VK_SUCCESS);
	assert(num_phys_devices == physical_devices.size());
	assert(selected_gpu() < (int)num_phys_devices);
	selected_physical_device = physical_devices[selected_gpu()];
	ILOG("Found %d physical devices (selecting %d):", (int)num_phys_devices, selected_gpu());
	for (unsigned i = 0; i < num_phys_devices; i++)
	{
		VkPhysicalDeviceProperties devprops;
		wrap_vkGetPhysicalDeviceProperties(physical_devices[i], &devprops);
		ILOG("\t%u : %s (API %u.%u)", i, devprops.deviceName, VK_VERSION_MAJOR(devprops.apiVersion), VK_VERSION_MINOR(devprops.apiVersion));
	}

	uint32_t families = 0;
	wrap_vkGetPhysicalDeviceQueueFamilyProperties(selected_physical_device, &families, nullptr);
	device_VkQueueFamilyProperties.resize(families);
	wrap_vkGetPhysicalDeviceQueueFamilyProperties(selected_physical_device, &families, device_VkQueueFamilyProperties.data());
	for (unsigned i = 0; i < device_VkQueueFamilyProperties.size(); i++)
	{
		const VkQueueFamilyProperties& p = device_VkQueueFamilyProperties.at(i);
		if ((p.queueFlags & VK_QUEUE_GRAPHICS_BIT) && (p.queueFlags & VK_QUEUE_COMPUTE_BIT) && (p.queueFlags & VK_QUEUE_TRANSFER_BIT)) selected_queue_family_index = i;
		DLOG("Selected queue family: %d", selected_queue_family_index);
	}
	if (selected_queue_family_index == 0xdeadbeef) ABORT("No valid queue family found!");

	if (!callback_initialized && wrap_vkCreateDebugReportCallbackEXT && has_debug_report)
	{
		VkDebugReportCallbackCreateInfoEXT drcinfo = {};
		drcinfo.sType = VK_STRUCTURE_TYPE_DEBUG_REPORT_CALLBACK_CREATE_INFO_EXT;
		drcinfo.flags = VK_DEBUG_REPORT_INFORMATION_BIT_EXT | VK_DEBUG_REPORT_WARNING_BIT_EXT | VK_DEBUG_REPORT_ERROR_BIT_EXT;
		drcinfo.pfnCallback = debug_report_callback;
		drcinfo.pUserData = nullptr;
		wrap_vkCreateDebugReportCallbackEXT(*pInstance, &drcinfo, pAllocator, &stored_callback);
		callback_initialized = true;
	}
}

const char* const* device_extensions(VkDeviceCreateInfo* sptr, lava_file_reader& reader, VkPhysicalDevice physicalDevice, uint32_t& len)
{
	bool trace_has_frame_boundary = false;
	static std::vector<const char *> dst;
	static std::vector<std::string> backing;
	const char* const* stored = reader.read_string_array(len); // all extensions used in original
	if (!reader.run) return stored;
	const std::vector<const char*> do_not_copy = {
		VK_KHR_SWAPCHAIN_EXTENSION_NAME, VK_KHR_GET_MEMORY_REQUIREMENTS_2_EXTENSION_NAME,
		VK_KHR_DEDICATED_ALLOCATION_EXTENSION_NAME, VK_EXT_PIPELINE_CREATION_FEEDBACK_EXTENSION_NAME,
		VK_EXT_PIPELINE_CREATION_CACHE_CONTROL_EXTENSION_NAME,
		VK_TRACETOOLTEST_OBJECT_PROPERTY_EXTENSION_NAME, VK_EXT_TOOLING_INFO_EXTENSION_NAME,
		VK_TRACETOOLTEST_TRACE_HELPERS_EXTENSION_NAME, VK_TRACETOOLTEST_TRACE_HELPERS2_EXTENSION_NAME
	};

	dst.clear();
	backing.clear();

	// Copy over all except platform-specific extensions and potential duplicates
	for (unsigned i = 0; i < len; i++)
	{
		bool nocopy = false;
		for (unsigned j = 0; j < do_not_copy.size(); j++)
		{
			if (strcmp(stored[i], do_not_copy[j]) == 0)
			{
				nocopy = true;
				break;
			}
		}

		if (strcmp(stored[i], "VK_EXT_frame_boundary") == 0)
		{
			trace_has_frame_boundary = true;
			nocopy = true; // add it later
		}

		// Sanity check
		if (is_noscreen() && strcmp(stored[i], "VK_KHR_display_swapchain") == 0)
		{
			ABORT("Cannot use VK_KHR_display_swapchain with none wsi yet");
		}

		if (!nocopy)
		{
			backing.push_back(stored[i]);
		}
	}

	// Find supported extensions
	uint32_t propertyCount = 0;
	VkResult result = wrap_vkEnumerateDeviceExtensionProperties(selected_physical_device, nullptr, &propertyCount, nullptr);
	assert(result == VK_SUCCESS);
	std::vector<VkExtensionProperties> supported_extensions(propertyCount);
	result = wrap_vkEnumerateDeviceExtensionProperties(selected_physical_device, nullptr, &propertyCount, supported_extensions.data());
	assert(result == VK_SUCCESS);
	bool has_swapchain = false;
	for (const VkExtensionProperties& s : supported_extensions)
	{
		if (strcmp(s.extensionName, VK_KHR_SWAPCHAIN_EXTENSION_NAME) == 0) has_swapchain = true;
		if (strcmp(s.extensionName, VK_EXT_PIPELINE_CREATION_FEEDBACK_EXTENSION_NAME) == 0) has_pipeline_feedback = true;
		if (strcmp(s.extensionName, VK_EXT_PIPELINE_CREATION_CACHE_CONTROL_EXTENSION_NAME) == 0) has_pipeline_control = true;
		if (strcmp(s.extensionName, VK_KHR_DEDICATED_ALLOCATION_EXTENSION_NAME) == 0) has_dedicated_allocation++;
		if (strcmp(s.extensionName, VK_KHR_GET_MEMORY_REQUIREMENTS_2_EXTENSION_NAME) == 0) has_dedicated_allocation++;
		if (strcmp(s.extensionName, VK_EXT_FRAME_BOUNDARY_EXTENSION_NAME) == 0) host_has_frame_boundary = true;
	}
	if (!has_swapchain) ABORT("No swapchain extension found - cannot proceed!");

	if (!host_has_frame_boundary && trace_has_frame_boundary)
	{
		ILOG("Replay host does not have frame boundary but trace does -- removing it from the replay!");
		purge_extension_parent(sptr, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAME_BOUNDARY_FEATURES_EXT);
	}
	else if (trace_has_frame_boundary)
	{
		backing.push_back(VK_EXT_FRAME_BOUNDARY_EXTENSION_NAME);
	}

	// Add device extensions
	backing.push_back(VK_KHR_SWAPCHAIN_EXTENSION_NAME);
	if (use_dedicated_allocation())
	{
		if (has_dedicated_allocation < 2) ABORT("No dedicated allocation support found - aborting!");
		backing.push_back(VK_KHR_GET_MEMORY_REQUIREMENTS_2_EXTENSION_NAME);
		backing.push_back(VK_KHR_DEDICATED_ALLOCATION_EXTENSION_NAME);
	}

	if (has_pipeline_feedback)
	{
		backing.push_back(VK_EXT_PIPELINE_CREATION_FEEDBACK_EXTENSION_NAME);
		DLOG("Enabling pipeline creation feedback extension");
	}

	if (has_pipeline_control)
	{
		backing.push_back(VK_EXT_PIPELINE_CREATION_CACHE_CONTROL_EXTENSION_NAME);
		DLOG("Enabling pipeline creation cache control extension");
	}

	dst.resize(backing.size());
	for (uint32_t i = 0; i < backing.size(); i++)
	{
		dst[i] = backing[i].data();
	}
	len = backing.size();

	DLOG("Enabling %u device extensions:", len);
	for (auto ext_name : backing)
	{
		DLOG("\t %s", ext_name.c_str());
	}

	return dst.data();
}

const char* const* instance_extensions(lava_file_reader& reader, uint32_t& len)
{
	static std::vector<const char *> dst;
	static std::vector<std::string> backing;
	const std::vector<const char*> do_not_copy = {
		VK_KHR_SURFACE_EXTENSION_NAME, "VK_KHR_xcb_surface", "VK_KHR_xlib_surface", VK_KHR_DISPLAY_EXTENSION_NAME,
		"VK_KHR_wayland_surface", "VK_KHR_mir_surface", "VK_KHR_android_surface", "VK_KHR_win32_surface",
		"VK_EXT_headless_surface"
	};
	const char* const* stored = reader.read_string_array(len);
	if (!reader.run) return stored;

	backing.clear();
	dst.clear();

	uint32_t propertyCount = 0;
	VkResult result = wrap_vkEnumerateInstanceExtensionProperties(nullptr, &propertyCount, nullptr);
	assert(result == VK_SUCCESS);
	std::vector<VkExtensionProperties> supported_extensions(propertyCount);
	result = wrap_vkEnumerateInstanceExtensionProperties(nullptr, &propertyCount, supported_extensions.data());
	assert(result == VK_SUCCESS);
	bool has_surface = false;
	DLOG("Supported instance extensions on replay host:");
	for (const VkExtensionProperties& s : supported_extensions)
	{
		if (strcmp(s.extensionName, VK_KHR_SURFACE_EXTENSION_NAME) == 0) has_surface = true;
		if (strcmp(s.extensionName, VK_EXT_DEBUG_REPORT_EXTENSION_NAME) == 0) has_debug_report = true;
		if (strcmp(s.extensionName, VK_EXT_DEBUG_UTILS_EXTENSION_NAME) == 0) has_debug_utils = true;
		DLOG("\t%s", s.extensionName);
	}
	if (!has_debug_report && is_debug()) ELOG("Warning: Debug report extension missing - debug mode will not be fully operational!");
	if (!has_debug_report && is_validation()) ELOG("Warning: Debug report extension missing - validation layer will not be able to report anything!");
	assert(has_surface);

	// Copy over all except platform-specific extensions and potential duplicates
	for (unsigned i = 0; i < len; i++)
	{
		bool nocopy = false;
		for (unsigned j = 0; j < do_not_copy.size(); j++)
		{
			if (strcmp(stored[i], do_not_copy[j]) == 0)
			{
				nocopy = true;
				break;
			}
		}

		if (is_noscreen() && strcmp(stored[i], "VK_KHR_display") == 0)
		{
			ABORT("Cannot use VK_KHR_display with none wsi yet");
		}

		if (!nocopy)
		{
			backing.push_back(stored[i]);
		}
	}

	// Add instance extensions
	backing.push_back(VK_KHR_SURFACE_EXTENSION_NAME);
	if (is_debug() || is_validation())
	{
		if (has_debug_report) backing.push_back(VK_EXT_DEBUG_REPORT_EXTENSION_NAME);
	}
#ifdef VK_USE_PLATFORM_ANDROID_KHR
	backing.push_back(VK_KHR_ANDROID_SURFACE_EXTENSION_NAME);
#else
	const char* winsys = window_winsys();
#ifdef VK_USE_PLATFORM_XCB_KHR
	if (strcmp(winsys, "xcb") == 0 && !is_noscreen())
	{
		backing.push_back(VK_KHR_XCB_SURFACE_EXTENSION_NAME);
	}
#endif
#ifdef VK_USE_PLATFORM_XLIB_KHR
	if (strcmp(winsys, "x11") == 0 && !is_noscreen())
	{
		backing.push_back(VK_KHR_XLIB_SURFACE_EXTENSION_NAME);
	}
#endif
	if (strcmp(winsys, "headless") == 0 && !is_noscreen())
	{
		backing.push_back("VK_EXT_headless_surface");
	}
#endif

	dst.resize(backing.size());
	for (uint32_t i = 0; i < backing.size(); i++)
	{
		dst[i] = backing[i].data();
	}
	len = backing.size();

	DLOG("Enabling %u instance extensions:", len);
	for (auto ext_name : backing)
	{
		DLOG("\t %s", ext_name.c_str());
	}

	return dst.data();
}

// for completeness - but this part of the API is never used
const char* const* device_layers(lava_file_reader& reader, uint32_t& len)
{
	const char* const* retval = reader.read_string_array(len);
	return retval;
}

const char* const* instance_layers(lava_file_reader& reader, uint32_t& len)
{
	static std::vector<const char *> dst;
	static std::vector<std::string> backing;
	const char* const* retval = reader.read_string_array(len);
	if (!reader.run) return retval;

	backing.clear();
	dst.clear();

	// Add validation layers, if requested
	uint32_t propertyCount = 0;
	VkResult result = wrap_vkEnumerateInstanceLayerProperties(&propertyCount, nullptr);
	assert(result == VK_SUCCESS);
	std::vector<VkLayerProperties> supported_layers(propertyCount);
	result = wrap_vkEnumerateInstanceLayerProperties(&propertyCount, supported_layers.data());
	assert(result == VK_SUCCESS);
	DLOG("Supported instance layers on replay host:");
	for (const VkLayerProperties& s : supported_layers)
	{
		DLOG("\t%s - %s", s.layerName, s.description);
		if (is_validation() && strcmp(s.layerName, "VK_LAYER_KHRONOS_validation") == 0)
		{
			backing.push_back(s.layerName);
			ILOG("Enabling validation layer");
		}
	}

	len = backing.size();

	// Resize everything else to match
	dst.resize(len);
	for (uint32_t i = 0; i < backing.size(); i++)
	{
		dst[i] = backing[i].data();
	}

	ILOG("Enabling %u layers:", len);
	for (auto l_name : backing)
	{
		ILOG("\t %s", l_name.c_str());
	}

	return dst.data();
}

/// 'instance' is not safe to use here, since it has already been destroyed
void replay_post_vkDestroyInstance(lava_file_reader& reader, VkInstance instance, const VkAllocationCallbacks* pAllocator)
{
	if (instance != VK_NULL_HANDLE)
	{
		reader.parent->finalize(false);
		callback_initialized = false;
		stored_instance = VK_NULL_HANDLE;
		reset_all();
	}
}

void replay_pre_vkDestroyDevice(lava_file_reader& reader, VkDevice device, const VkAllocationCallbacks* pAllocator)
{
	if (device != VK_NULL_HANDLE)
	{
		wrap_vkDeviceWaitIdle(device);
		suballoc_destroy(device);
		selected_physical_device = VK_NULL_HANDLE;
	}
}

void replay_pre_vkDestroyInstance(lava_file_reader& reader, VkInstance instance, const VkAllocationCallbacks* pAllocator)
{
	if (stored_callback != VK_NULL_HANDLE)
	{
		wrap_vkDestroyDebugReportCallbackEXT(instance, stored_callback, pAllocator);
		stored_callback = VK_NULL_HANDLE;
	}
}

void retrace_vkGetDeviceProcAddr(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	VkDevice device = index_to_VkDevice.at(device_index);
	const char* pName = reader.read_string();
	PFN_vkVoidFunction ptr = nullptr;
	if (reader.run) wrap_vkGetDeviceProcAddr(device, pName);
}

void retrace_vkGetInstanceProcAddr(lava_file_reader& reader)
{
	const uint32_t instance_index = reader.read_handle();
	VkInstance instance = index_to_VkInstance.at(instance_index);
	const char* pName = reader.read_string();
	PFN_vkVoidFunction ptr = nullptr;
	if (reader.run) wrap_vkGetInstanceProcAddr(instance, pName);
}

static void retrace_vkFrameEndTRACETOOLTEST(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	VkDevice device = index_to_VkDevice.at(device_index);
	DLOG("End of thread %u local frame %d signaled by vkFrameEndTRACETOOLTEST", reader.thread_index(), reader.current.frame);
	reader.new_frame();
}

void retrace_vkGetDeviceTracingObjectPropertyTRACETOOLTEST(lava_file_reader& reader)
{
	assert(false);
}

void retrace_vkSyncBufferTRACETOOLTEST(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	const uint32_t buffer_index = reader.read_handle();
}

void retrace_vkAssertBufferTRACETOOLTEST(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	const uint32_t buffer_index = reader.read_handle();
	const VkDeviceSize offset = reader.read_uint64_t();
	VkDeviceSize size = reader.read_uint64_t();
	const uint32_t checksum = reader.read_uint32_t();
	trackedobject& tbuf = VkBuffer_index.at(buffer_index);
	VkDevice device = index_to_VkDevice.at(device_index);
	suballoc_location loc = suballoc_find_buffer_memory(buffer_index);
	if (size == VK_WHOLE_SIZE)
	{
		size = tbuf.size - offset; // set to remaining size
	}
	uint8_t* ptr = nullptr;
	if (!reader.run) return;
	VkResult result = wrap_vkMapMemory(device, loc.memory, loc.offset, tbuf.size, 0, (void**)&ptr);
	assert(result == VK_SUCCESS);
	uint32_t checksum_new = adler32((unsigned char*)ptr + offset, size);
	NEVER("buffer %u validation size=%u off=%u memoff=%u origchecksum=%u newchecksum=%u [first byte is %u, last byte is %u]", buffer_index, (unsigned)size, (unsigned)offset, (unsigned)loc.offset, checksum, checksum_new, ptr[0], ptr[tbuf.size-1]);
	wrap_vkUnmapMemory(device, loc.memory);
	assert(checksum == checksum_new || is_blackhole_mode());
}

void read_VkAddressRemapTRACETOOLTEST(lava_file_reader& reader, VkAddressRemapTRACETOOLTEST* sptr)
{
	sptr->sType = (VkStructureType)reader.read_uint32_t();
	assert(sptr->sType == VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
	read_extension(reader, (VkBaseOutStructure**)&sptr->pNext);
	sptr->count = reader.read_uint32_t();
	const bool pOffsets_opt = reader.read_uint8_t();
	sptr->pOffsets = nullptr;
	if (pOffsets_opt)
	{
		VkDeviceSize* backing = reader.pool.allocate<VkDeviceSize>(sptr->count);
		memset(backing, 0, sptr->count * sizeof(VkDeviceSize));
		reader.read_array(backing, sptr->count);
		sptr->pOffsets = backing;
	}
	DLOG("Got a memory markup struct with count=%u", (unsigned)sptr->count);
}

static void translate_addresses(lava_file_reader& reader, uint32_t count, VkDeviceSize* pOffsets, void* ptr)
{
	for (uint32_t i = 0; i < count; i++)
	{
		const uint64_t offset = pOffsets[i];
		uint64_t* addr = (uint64_t*)(((char*)ptr) + offset);
		const uint64_t current = *addr;
		const uint64_t newval = reader.parent->device_address_remapping.translate_address(current);
		DLOG("%u: Changing memory value at offset %lu from %lu to %lu", (unsigned)i, (unsigned long)offset, (unsigned long)current, (unsigned long)newval);
		*addr = newval;
	}
}

static void handle_VkWriteDescriptorSets(lava_file_reader& reader, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites, bool clear)
{
	for (unsigned i = 0; i < descriptorWriteCount; i++)
	{
		const VkDescriptorType type = pDescriptorWrites[i].descriptorType;
		const uint32_t descriptorset_index = index_to_VkDescriptorSet.index(pDescriptorWrites[i].dstSet);
		auto& tds = VkDescriptorSet_index.at(descriptorset_index);
		// TBD I do not think this is correct. We are allowed to keep descriptor state for bindings not touched here from a previous call.
		// Not sure how to handle this well, and not seen any content where this breaks anything, but should fix it...
		if (clear) { tds.bound_buffers.clear(); tds.dynamic_buffers.clear(); }
	}
	for (unsigned i = 0; i < descriptorWriteCount; i++)
	{
		const VkDescriptorType type = pDescriptorWrites[i].descriptorType;
		const uint32_t descriptorset_index = index_to_VkDescriptorSet.index(pDescriptorWrites[i].dstSet);
		auto& tds = VkDescriptorSet_index.at(descriptorset_index);

		switch (type)
		{
		case VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER:
		case VK_DESCRIPTOR_TYPE_STORAGE_BUFFER:
			for (unsigned j = 0; j < pDescriptorWrites[i].descriptorCount; j++)
			{
				if (pDescriptorWrites[i].pBufferInfo[j].buffer == VK_NULL_HANDLE) continue;
				const uint32_t buffer_index = index_to_VkBuffer.index(pDescriptorWrites[i].pBufferInfo[j].buffer);
				auto& buffer_data = VkBuffer_index.at(buffer_index);
				VkDeviceSize size = pDescriptorWrites[i].pBufferInfo[j].range;
				if (size == VK_WHOLE_SIZE) size = buffer_data.size - pDescriptorWrites[i].pBufferInfo[j].offset;
				tds.bound_buffers[j] = buffer_access { &buffer_data, pDescriptorWrites[i].pBufferInfo[j].offset, size };
			}
			break;
		case VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC:
		case VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC:
			for (unsigned j = 0; j < pDescriptorWrites[i].descriptorCount; j++)
			{
				tds.dynamic_buffers[j] = pDescriptorWrites[i].pBufferInfo[j];
			}
			break;
		case VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK: // Provided by VK_VERSION_1_3
			{
				auto* ptr = (VkWriteDescriptorSetInlineUniformBlock*)find_extension(pDescriptorWrites[i].pNext, VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK);
				assert(ptr);
				assert(ptr->sType == VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK);
				// TBD
			}
			break;
		case VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_KHR: // Provided by VK_KHR_acceleration_structure
			{
				auto* ptr = (VkWriteDescriptorSetAccelerationStructureKHR *)find_extension(pDescriptorWrites[i].pNext, VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_KHR);
				assert(ptr);
				assert(ptr->sType == VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_KHR);
				assert(ptr->accelerationStructureCount == pDescriptorWrites[i].descriptorCount);
				// TBD
			}
			break;
		case VK_DESCRIPTOR_TYPE_MUTABLE_EXT: // Provided by VK_EXT_mutable_descriptor_type
			ABORT("vkUpdateDescriptorSets using VK_EXT_mutable_descriptor_type not yet implemented");
			break;
		case VK_DESCRIPTOR_TYPE_BLOCK_MATCH_IMAGE_QCOM: // Provided by VK_QCOM_image_processing
		case VK_DESCRIPTOR_TYPE_SAMPLE_WEIGHT_IMAGE_QCOM: // Provided by VK_QCOM_image_processing
			ABORT("VK_QCOM_image_processing not supported");
			break;
		case VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_NV: // Provided by VK_NV_ray_tracing
			ABORT("VK_NV_ray_tracing not supported");
			break;
		default:
			break;
		case VK_DESCRIPTOR_TYPE_MAX_ENUM:
			ABORT("Bad descriptor type in vkUpdateDescriptorSets");
			break;
		}
	}
}

void replay_postprocess_vkCmdPushDescriptorSetKHR(lava_file_reader& reader, VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites)
{
	assert(false);
	//trackedcommand cmd { VKCMDPUSHDESCRIPTORSETKHR };
	// TBD - need to delay
	// handle_VkWriteDescriptorSets(writer, descriptorWriteCount, pDescriptorWrites, false);
}

void replay_postprocess_vkCmdPushDescriptorSet2KHR(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkPushDescriptorSetInfoKHR* pPushDescriptorSetInfo)
{
	assert(false);
	//trackedcommand cmd { VKCMDPUSHDESCRIPTORSET2KHR };
	// TBD - need to delay
	//handle_VkWriteDescriptorSets(writer, pPushDescriptorSetInfo->descriptorWriteCount, pPushDescriptorSetInfo->pDescriptorWrites, false);
}

void replay_postprocess_vkUpdateDescriptorSets(lava_file_reader& reader, VkDevice device, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const VkCopyDescriptorSet* pDescriptorCopies)
{
	handle_VkWriteDescriptorSets(reader, descriptorWriteCount, pDescriptorWrites, true);

	// TBD handle copy
	assert(descriptorCopyCount == 0);
}

void replay_postprocess_vkCmdBindDescriptorSets(lava_file_reader& reader, VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout,
	uint32_t firstSet, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets)
{
	const uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDBINDDESCRIPTORSETS };
	cmd.data.bind_descriptorsets.pipelineBindPoint = pipelineBindPoint;
	cmd.data.bind_descriptorsets.layout = layout;
	cmd.data.bind_descriptorsets.firstSet = firstSet;
	cmd.data.bind_descriptorsets.descriptorSetCount = descriptorSetCount;
	if (descriptorSetCount > 0)
	{
		cmd.data.bind_descriptorsets.pDescriptorSets = (uint32_t*)malloc(descriptorSetCount * sizeof(uint32_t));
		for (uint32_t i = 0; i < descriptorSetCount; i++)
		{
			const uint32_t descriptorset_index = index_to_VkDescriptorSet.index(pDescriptorSets[i]);
			cmd.data.bind_descriptorsets.pDescriptorSets[i] = descriptorset_index;
		}
	}
	else cmd.data.bind_descriptorsets.pDescriptorSets = nullptr;
	cmd.data.bind_descriptorsets.dynamicOffsetCount = dynamicOffsetCount;
	if (dynamicOffsetCount > 0 && pDynamicOffsets)
	{
		cmd.data.bind_descriptorsets.pDynamicOffsets = (uint32_t*)malloc(dynamicOffsetCount * sizeof(uint32_t));
		memcpy(cmd.data.bind_descriptorsets.pDynamicOffsets, pDynamicOffsets, dynamicOffsetCount * sizeof(uint32_t));
	}
	else cmd.data.bind_descriptorsets.pDynamicOffsets = nullptr;
	cmdbuffer_data.commands.push_back(cmd);
}

void replay_postprocess_vkCmdBindDescriptorSets2KHR(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkBindDescriptorSetsInfoKHR* pBindDescriptorSetsInfo)
{
	if ((pBindDescriptorSetsInfo->stageFlags & VK_SHADER_STAGE_VERTEX_BIT) || (pBindDescriptorSetsInfo->stageFlags & VK_SHADER_STAGE_FRAGMENT_BIT))
	{
		replay_postprocess_vkCmdBindDescriptorSets(reader, commandBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS, pBindDescriptorSetsInfo->layout,
			pBindDescriptorSetsInfo->firstSet, pBindDescriptorSetsInfo->descriptorSetCount, pBindDescriptorSetsInfo->pDescriptorSets,
			pBindDescriptorSetsInfo->dynamicOffsetCount, pBindDescriptorSetsInfo->pDynamicOffsets);
	}
	if (pBindDescriptorSetsInfo->stageFlags & VK_SHADER_STAGE_COMPUTE_BIT)
	{
		replay_postprocess_vkCmdBindDescriptorSets(reader, commandBuffer, VK_PIPELINE_BIND_POINT_COMPUTE, pBindDescriptorSetsInfo->layout,
			pBindDescriptorSetsInfo->firstSet, pBindDescriptorSetsInfo->descriptorSetCount, pBindDescriptorSetsInfo->pDescriptorSets,
			pBindDescriptorSetsInfo->dynamicOffsetCount, pBindDescriptorSetsInfo->pDynamicOffsets);
	}
}

void replay_postprocess_vkCmdBindDescriptorSets2(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkBindDescriptorSetsInfoKHR* pBindDescriptorSetsInfo)
{
	replay_postprocess_vkCmdBindDescriptorSets2KHR(reader, commandBuffer, pBindDescriptorSetsInfo);
}

void replay_postprocess_vkQueueSubmit2(lava_file_reader& reader, VkResult result, VkQueue queue, uint32_t submitCount, const VkSubmitInfo2* pSubmits, VkFence fence)
{
	for (uint32_t i = 0; i < submitCount; i++)
	{
		for (uint32_t j = 0; j < pSubmits[i].commandBufferInfoCount; j++)
		{
			execute_commands(reader, pSubmits[i].pCommandBufferInfos[j].commandBuffer);
		}
	}
}

void replay_postprocess_vkQueueSubmit2KHR(lava_file_reader& reader, VkResult result, VkQueue queue, uint32_t submitCount, const VkSubmitInfo2KHR* pSubmits, VkFence fence)
{
	replay_pre_vkQueueSubmit2(reader, queue, submitCount, pSubmits, fence);
}

void replay_postprocess_vkQueueSubmit(lava_file_reader& reader, VkResult result, VkQueue queue, uint32_t submitCount, const VkSubmitInfo* pSubmits, VkFence fence)
{
	for (uint32_t i = 0; i < submitCount; i++)
	{
		for (uint32_t j = 0; j < pSubmits[i].commandBufferCount; j++)
		{
			execute_commands(reader, pSubmits[i].pCommandBuffers[j]);
		}
	}
}

static void replay_postprocess_vkCmdBindPipeline(lava_file_reader& reader, VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline)
{
	const uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	const uint32_t pipeline_index = index_to_VkPipeline.index(pipeline);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDBINDPIPELINE };
	cmd.data.bind_pipeline.pipelineBindPoint = pipelineBindPoint;
	cmd.data.bind_pipeline.pipeline_index = pipeline_index;
	cmdbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_draw_command(lava_file_reader& reader, uint32_t commandbuffer_index, trackedcmdbuffer& commandbuffer_data)
{
	trackedcommand cmd { VKCMDDRAW };
	commandbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_raytracing_command(lava_file_reader& reader, uint32_t commandbuffer_index, trackedcmdbuffer& commandbuffer_data)
{
	trackedcommand cmd { VKCMDTRACERAYSKHR };
	commandbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_compute_command(lava_file_reader& reader, uint32_t commandbuffer_index, trackedcmdbuffer& commandbuffer_data)
{
	trackedcommand cmd { VKCMDDISPATCH };
	commandbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_vkCmdUpdateBuffer(VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize dataSize, const void* pData)
{
	uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDUPDATEBUFFER };
	cmd.data.update_buffer.size = dataSize;
	cmd.data.update_buffer.offset = dstOffset;
	cmd.data.update_buffer.buffer_index = index_to_VkBuffer.index(dstBuffer);
	cmd.data.update_buffer.values = (char*)malloc(dataSize);
	memcpy(cmd.data.update_buffer.values, pData, dataSize);
	cmdbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_vkCmdCopyBuffer(VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferCopy* pRegions)
{
	uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDCOPYBUFFER };
	cmd.data.copy_buffer.src_buffer_index = index_to_VkBuffer.index(srcBuffer);
	cmd.data.copy_buffer.dst_buffer_index = index_to_VkBuffer.index(dstBuffer);
	cmd.data.copy_buffer.regionCount = regionCount;
	cmd.data.copy_buffer.pRegions = (VkBufferCopy*)malloc(regionCount * sizeof(VkBufferCopy));
	memcpy(cmd.data.copy_buffer.pRegions, pRegions, regionCount * sizeof(VkBufferCopy));
	cmdbuffer_data.commands.push_back(cmd);
}

static void replay_postprocess_vkCmdCopyBuffer2(VkCommandBuffer commandBuffer, const VkCopyBufferInfo2* pCopyBufferInfo)
{
	uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDCOPYBUFFER };
	cmd.data.copy_buffer.src_buffer_index = index_to_VkBuffer.index(pCopyBufferInfo->srcBuffer);
	cmd.data.copy_buffer.dst_buffer_index = index_to_VkBuffer.index(pCopyBufferInfo->dstBuffer);
	cmd.data.copy_buffer.regionCount = pCopyBufferInfo->regionCount;
	cmd.data.copy_buffer.pRegions = (VkBufferCopy*)malloc(pCopyBufferInfo->regionCount * sizeof(VkBufferCopy));
	memcpy(cmd.data.copy_buffer.pRegions, pCopyBufferInfo->pRegions, pCopyBufferInfo->regionCount * sizeof(VkBufferCopy));
	cmdbuffer_data.commands.push_back(cmd);
}

static void postprocess_push_constants(lava_file_reader& reader, VkCommandBuffer commandBuffer, uint32_t offset, uint32_t size, const void* pValues)
{
	uint32_t cmdbuffer_index = index_to_VkCommandBuffer.index(commandBuffer);
	auto& cmdbuffer_data = VkCommandBuffer_index.at(cmdbuffer_index);
	trackedcommand cmd { VKCMDPUSHCONSTANTS };
	cmd.data.push_constants.offset = offset;
	cmd.data.push_constants.size = size;
	cmd.data.push_constants.values = (char*)malloc(size);
	memcpy(cmd.data.push_constants.values, pValues, size);
	cmdbuffer_data.commands.push_back(cmd);
}

void replay_postprocess_vkCmdPushConstants(lava_file_reader& reader, VkCommandBuffer commandBuffer, VkPipelineLayout layout, VkShaderStageFlags stageFlags, uint32_t offset, uint32_t size, const void* pValues)
{
	postprocess_push_constants(reader, commandBuffer, offset, size, pValues);
}

void replay_postprocess_vkCmdPushConstants2KHR(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkPushConstantsInfoKHR* pPushConstantsInfo)
{
	postprocess_push_constants(reader, commandBuffer, pPushConstantsInfo->offset, pPushConstantsInfo->size, pPushConstantsInfo->pValues);
}

void replay_postprocess_vkCmdPushConstants2(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkPushConstantsInfoKHR* pPushConstantsInfo)
{
	replay_postprocess_vkCmdPushConstants2KHR(reader, commandBuffer, pPushConstantsInfo);
}

static void copy_shader_stage(shader_stage& stage, const VkPipelineShaderStageCreateInfo& info)
{
	stage.flags = info.flags;
	stage.module = info.module;
	stage.name = info.pName;
	stage.stage = info.stage;
	if (info.pSpecializationInfo)
	{
		stage.specialization_constants.resize(info.pSpecializationInfo->mapEntryCount);
		memcpy(stage.specialization_constants.data(), info.pSpecializationInfo->pMapEntries, info.pSpecializationInfo->mapEntryCount * sizeof(uint32_t));
		stage.specialization_data.resize(info.pSpecializationInfo->dataSize);
		memcpy(stage.specialization_data.data(), info.pSpecializationInfo->pData, info.pSpecializationInfo->dataSize);
	}
}

void replay_postprocess_vkCreateComputePipelines(lava_file_reader& reader, VkResult result, VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount,
	const VkComputePipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		const uint32_t pipeline_index = index_to_VkPipeline.index(pPipelines[i]);
		trackedpipeline& pipeline_data = VkPipeline_index.at(pipeline_index);
		pipeline_data.shader_stages.resize(1);
		copy_shader_stage(pipeline_data.shader_stages[0], pCreateInfos[i].stage);
	}
}

void replay_postprocess_vkCreateGraphicsPipelines(lava_file_reader& reader, VkResult result, VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount,
	const VkGraphicsPipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		const uint32_t pipeline_index = index_to_VkPipeline.index(pPipelines[i]);
		trackedpipeline& pipeline_data = VkPipeline_index.at(pipeline_index);
		pipeline_data.shader_stages.resize(pCreateInfos[i].stageCount);
		for (uint32_t stage = 0; stage < pCreateInfos[i].stageCount; stage++)
		{
			copy_shader_stage(pipeline_data.shader_stages[0], pCreateInfos[i].pStages[stage]);
		}
	}
}


void replay_postprocess_vkCreateRayTracingPipelinesKHR(lava_file_reader& reader, VkResult result, VkDevice device, VkDeferredOperationKHR deferredOperation, VkPipelineCache pipelineCache,
	uint32_t createInfoCount, const VkRayTracingPipelineCreateInfoKHR* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		const uint32_t pipeline_index = index_to_VkPipeline.index(pPipelines[i]);
		trackedpipeline& pipeline_data = VkPipeline_index.at(pipeline_index);
		pipeline_data.shader_stages.resize(pCreateInfos[i].stageCount);
		for (uint32_t stage = 0; stage < pCreateInfos[i].stageCount; stage++)
		{
			copy_shader_stage(pipeline_data.shader_stages[0], pCreateInfos[i].pStages[stage]);
		}
	}
}

void replay_pre_vkCmdPushConstants2KHR(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkPushConstantsInfoKHR* pPushConstantsInfo)
{
	assert(pPushConstantsInfo);
	const VkAddressRemapTRACETOOLTEST* remap = (const VkAddressRemapTRACETOOLTEST*)find_extension(pPushConstantsInfo, VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
	if (!remap) return; // nothing to do here
	assert(pPushConstantsInfo->pValues);
	assert(pPushConstantsInfo->size >= remap->count);
	translate_addresses(reader, remap->count, remap->pOffsets, const_cast<void*>(pPushConstantsInfo->pValues));
	// make sure we don't leak this to the driver, as this would break validation
	purge_extension_parent(const_cast<VkPushConstantsInfoKHR*>(pPushConstantsInfo), VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
}

void replay_pre_vkCmdPushConstants2(lava_file_reader& reader, VkCommandBuffer commandBuffer, const VkPushConstantsInfoKHR* pPushConstantsInfo)
{
	replay_pre_vkCmdPushConstants2KHR(reader, commandBuffer, pPushConstantsInfo);
}

void replay_pre_vkCreateComputePipelines(lava_file_reader& reader, VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount,
	const VkComputePipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		const VkAddressRemapTRACETOOLTEST* remap = (const VkAddressRemapTRACETOOLTEST*)find_extension(&pCreateInfos[i].stage, VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
		if (!remap) continue; // nothing to do here

		assert(pCreateInfos[i].stage.pSpecializationInfo != nullptr);
		assert(pCreateInfos[i].stage.pSpecializationInfo->pData != nullptr);
		assert(pCreateInfos[i].stage.pSpecializationInfo->dataSize >= remap->count);

		translate_addresses(reader, remap->count, remap->pOffsets, const_cast<void*>(pCreateInfos[i].stage.pSpecializationInfo->pData));

		// make sure we don't leak this to the driver, as this would break validation
		purge_extension_parent(const_cast<VkPipelineShaderStageCreateInfo*>(&pCreateInfos[i].stage), VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
	}
}

void replay_pre_vkCreateGraphicsPipelines(lava_file_reader& reader, VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount,
	const VkGraphicsPipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		for (uint32_t stage = 0; stage < pCreateInfos[i].stageCount; stage++)
		{
			const VkAddressRemapTRACETOOLTEST* remap = (const VkAddressRemapTRACETOOLTEST*)find_extension(&pCreateInfos[i].pStages[stage], VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
			if (!remap) continue; // nothing to do here

			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo != nullptr);
			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo->pData != nullptr);
			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo->dataSize >= remap->count);

			translate_addresses(reader, remap->count, remap->pOffsets, const_cast<void*>(pCreateInfos[i].pStages[stage].pSpecializationInfo->pData));

			// make sure we don't leak this to the driver, as this would break validation
			purge_extension_parent(const_cast<VkPipelineShaderStageCreateInfo*>(&pCreateInfos[i].pStages[stage]), VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
		}
	}
}

void replay_pre_vkCreateRayTracingPipelinesKHR(lava_file_reader& reader, VkDevice device, VkDeferredOperationKHR deferredOperation, VkPipelineCache pipelineCache,
	uint32_t createInfoCount, const VkRayTracingPipelineCreateInfoKHR* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines)
{
	for (uint32_t i = 0; i < createInfoCount; i++)
	{
		for (uint32_t stage = 0; stage < pCreateInfos[i].stageCount; stage++)
		{
			const VkAddressRemapTRACETOOLTEST* remap = (const VkAddressRemapTRACETOOLTEST*)find_extension(&pCreateInfos[i].pStages[stage], VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
			if (!remap) continue; // nothing to do here

			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo != nullptr);
			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo->pData != nullptr);
			assert(pCreateInfos[i].pStages[stage].pSpecializationInfo->dataSize >= remap->count);

			translate_addresses(reader, remap->count, remap->pOffsets, const_cast<void*>(pCreateInfos[i].pStages[stage].pSpecializationInfo->pData));

			// make sure we don't leak this to the driver, as this would break validation
			purge_extension_parent(const_cast<VkPipelineShaderStageCreateInfo*>(&pCreateInfos[i].pStages[stage]), VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
		}
	}
}

static char* mem_map(lava_file_reader& reader, VkDevice device, const suballoc_location& loc)
{
	char* ptr = nullptr;
	if (reader.run)
	{
		VkResult result = wrap_vkMapMemory(device, loc.memory, loc.offset, loc.size, 0, (void**)&ptr);
		assert(result == VK_SUCCESS);
	}
	else
	{
		ptr = (char*)loc.memory;
	}
	if (loc.needs_init)
	{
		memset(ptr, 0, loc.size);
	}
	return ptr;
}

static void mem_unmap(lava_file_reader& reader, VkDevice device, const suballoc_location& loc, VkAddressRemapTRACETOOLTEST* ar, char* ptr)
{
	if (ar) translate_addresses(reader, ar->count, ar->pOffsets, ptr);
	if (loc.needs_flush && reader.run)
	{
		VkMappedMemoryRange flush = {};
		flush.sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE;
		flush.memory = loc.memory;
		flush.offset = loc.offset;
		flush.size = loc.size;
		wrap_vkFlushMappedMemoryRanges(device, 1, &flush);
	}
	if (reader.run) wrap_vkUnmapMemory(device, loc.memory);
}

VKAPI_ATTR void retrace_vkThreadBarrierTRACETOOLTEST(lava_file_reader& reader)
{
	const unsigned size = reader.read_uint32_t();
	for (int i = 0; i < (int)size; i++)
	{
		const unsigned call = reader.read_uint32_t();
		DLOG3("Thread barrier on thread %d, waiting for call %u on thread %d / %u", reader.thread_index(), call, i, size - 1);
		while (i != reader.thread_index() && call > reader.parent->thread_call_numbers->at(i).load(std::memory_order_relaxed)) usleep(1);
	}
	DLOG2("Passed thread barrier on thread %d, waited for %u threads", reader.thread_index(), size);
}

VKAPI_ATTR void retrace_vkUpdateBufferTRACETOOLTEST(lava_file_reader& reader)
{
	// Read
	const uint32_t device_index = reader.read_handle();
	const uint32_t buffer_index = reader.read_handle();
	VkUpdateMemoryInfoTRACETOOLTEST info = {};
	read_VkUpdateMemoryInfoTRACETOOLTEST(reader, &info);

	// Lookup
	VkDevice device = index_to_VkDevice.at(device_index);
	trackedbuffer& tbuf = VkBuffer_index.at(buffer_index);
	suballoc_location loc = suballoc_find_buffer_memory(buffer_index);
	VkAddressRemapTRACETOOLTEST* ar = (VkAddressRemapTRACETOOLTEST*)find_extension(&info, (VkStructureType)VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);

	// Verify
	assert(info.pData);
	assert(loc.memory);
	assert(tbuf.size);

	// Act
	char* ptr = mem_map(reader, device, loc);
	memcpy(ptr, info.pData, info.dataSize);
	if (reader.parent->remap)
	{
		reader.parent->find_address_candidates(tbuf, info.dataSize, info.pData, reader.current);
		if (ar) assert(tbuf.candidates.size() >= ar->count);
	}
	mem_unmap(reader, device, loc, ar, ptr);
	tbuf.last_modified = reader.current;
}

VKAPI_ATTR void retrace_vkUpdateImageTRACETOOLTEST(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	const uint32_t image_index = reader.read_handle();
	VkUpdateMemoryInfoTRACETOOLTEST info = {};
	read_VkUpdateMemoryInfoTRACETOOLTEST(reader, &info);

	// Lookup
	VkDevice device = index_to_VkDevice.at(device_index);
	trackedimage& timg = VkImage_index.at(image_index);
	suballoc_location loc = suballoc_find_image_memory(image_index);
	VkAddressRemapTRACETOOLTEST* ar = (VkAddressRemapTRACETOOLTEST*)find_extension(&info, VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);

	// Verify
	assert(info.pData);
	assert(loc.memory);
	assert(timg.size);

	// Act
	char* ptr = mem_map(reader, device, loc);
	memcpy(ptr, info.pData, info.dataSize);
	mem_unmap(reader, device, loc, ar, ptr);
	timg.last_modified = reader.current;
}

void read_VkUpdateMemoryInfoTRACETOOLTEST(lava_file_reader& reader, VkUpdateMemoryInfoTRACETOOLTEST* sptr)
{
	sptr->sType = (VkStructureType)reader.read_uint32_t();
	assert(sptr->sType == VK_STRUCTURE_TYPE_UPDATE_MEMORY_INFO_TRACETOOLTEST);
	read_extension(reader, (VkBaseOutStructure**)&sptr->pNext);
	sptr->dstOffset = reader.read_uint64_t();
	sptr->dataSize = reader.read_uint64_t();
	uint8_t pData_opt = reader.read_uint8_t();
	if (pData_opt)
	{
		uint8_t* backing = reader.pool.allocate<uint8_t>(sptr->dataSize);
		memset(backing, 0, sptr->dataSize);
		reader.read_array(backing, sptr->dataSize);
		sptr->pData = backing;
	}
}

VKAPI_ATTR void retrace_vkCmdUpdateBuffer2TRACETOOLTEST(lava_file_reader& reader)
{
	VkUpdateMemoryInfoTRACETOOLTEST info = {};
	const uint32_t commandbuffer_index = reader.read_handle();
	const uint32_t buffer_index = reader.read_handle();
	VkBuffer dstBuffer = index_to_VkBuffer.at(buffer_index);
	trackedobject& tbuf = VkBuffer_index.at(buffer_index);
	VkCommandBuffer commandBuffer = index_to_VkCommandBuffer.at(commandbuffer_index);
	read_VkUpdateMemoryInfoTRACETOOLTEST(reader, &info);
	VkAddressRemapTRACETOOLTEST* ar = (VkAddressRemapTRACETOOLTEST*)find_extension(&info, VK_STRUCTURE_TYPE_ADDRESS_REMAP_TRACETOOLTEST);
	// -- Execute --
	if (ar) translate_addresses(reader, ar->count, ar->pOffsets, const_cast<void*>(info.pData));
	if (reader.run) wrap_vkCmdUpdateBuffer(commandBuffer, dstBuffer, info.dstOffset, info.dataSize, info.pData);
	ILOG("Ran vkCmdUpdateBuffer2TRACETOOLTEST"); // TBD REMOVE ME
	tbuf.last_modified = reader.current;
}

void retrace_vkCmdBuildAccelerationStructuresIndirectKHR(lava_file_reader& reader)
{
	// -- Declarations --
	VkCommandBuffer commandBuffer = (VkCommandBuffer)0;
	uint32_t commandbuffer_index = 0;
	uint32_t infoCount = 0;
	uint8_t tmp_uuint8t = 0;
	VkAccelerationStructureBuildGeometryInfoKHR* pInfos = nullptr;
	VkAccelerationStructureBuildGeometryInfoKHR* pInfos_backing = nullptr;
	uint32_t tmp_uuint32t = 0;
	VkDeviceAddress* pIndirectDeviceAddresses = nullptr;
	uint64_t* tmp_uuint64t_ptr = nullptr;
	VkDeviceAddress* pIndirectDeviceAddresses_backing = nullptr;
	uint32_t* pIndirectStrides = nullptr;
	uint32_t** ppMaxPrimitiveCounts = nullptr;
	// -- Instructions --
	// -- Load --
	commandbuffer_index = reader.read_handle();
	commandBuffer = index_to_VkCommandBuffer.at(commandbuffer_index);
	infoCount = reader.read_uint32_t();
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load pInfos
	if (tmp_uuint8t)
	{
		pInfos_backing = reader.pool.allocate<VkAccelerationStructureBuildGeometryInfoKHR>(infoCount);
		memset(pInfos_backing, 0, infoCount * sizeof(VkAccelerationStructureBuildGeometryInfoKHR));
		for (unsigned sidx = 0; sidx < infoCount; sidx++) pInfos_backing[sidx].sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR;
		pInfos = pInfos_backing;
		for (unsigned sidx = 0; sidx < infoCount; sidx++) // varname=pInfos_backing
		{
			read_VkAccelerationStructureBuildGeometryInfoKHR(reader, &pInfos_backing[sidx]);
		}
	}
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load pIndirectDeviceAddresses
	if (tmp_uuint8t)
	{
		tmp_uuint32t = infoCount;
		if (tmp_uuint32t > 0)
		{
			tmp_uuint64t_ptr = reader.pool.allocate<uint64_t>(tmp_uuint32t);
			pIndirectDeviceAddresses_backing = reader.pool.allocate<VkDeviceAddress>(tmp_uuint32t);
			memset(pIndirectDeviceAddresses_backing, 0, tmp_uuint32t * sizeof(VkDeviceAddress));
			reader.read_array(tmp_uuint64t_ptr, tmp_uuint32t);
			for (size_t k1 = 0; k1 < tmp_uuint32t; k1++) pIndirectDeviceAddresses_backing[k1] = static_cast<VkDeviceAddress>(tmp_uuint64t_ptr[k1]);
			pIndirectDeviceAddresses = pIndirectDeviceAddresses_backing;
		}
		else pIndirectDeviceAddresses = nullptr;
	}
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load pIndirectStrides
	if (tmp_uuint8t)
	{
		if (infoCount > 0)
		{
			pIndirectStrides = reader.pool.allocate<uint32_t>(infoCount);
			reader.read_array(pIndirectStrides, infoCount); // array of dynamic length
		}
	}
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load ppMaxPrimitiveCounts
	if (tmp_uuint8t)
	{
		if (infoCount > 0)
		{
			ppMaxPrimitiveCounts = reader.pool.allocate<uint32_t*>(infoCount);
			reader.read_array(ppMaxPrimitiveCounts, infoCount);
			for (unsigned sidx = 0; sidx < infoCount; sidx++)
			{
				ppMaxPrimitiveCounts[sidx] = reader.pool.allocate<uint32_t>(pInfos[sidx].geometryCount);
				reader.read_array(ppMaxPrimitiveCounts[sidx], pInfos[sidx].geometryCount);
			}
		}
	}
	// -- Execute --
	if (reader.run) wrap_vkCmdBuildAccelerationStructuresIndirectKHR(commandBuffer, infoCount, pInfos, pIndirectDeviceAddresses, pIndirectStrides, ppMaxPrimitiveCounts);
	// -- Post --
}

static void read_VkAccelerationStructureBuildGeometryInfoKHR(lava_file_reader& reader, VkAccelerationStructureBuildGeometryInfoKHR* sptr)
{
	// -- Declarations --
	uint32_t accelerationstructurekhr_index = 0;
	uint32_t geometryCount = 0;
	uint8_t tmp_uuint8t = 0;
	VkAccelerationStructureGeometryKHR* pGeometries_backing = nullptr;
	VkAccelerationStructureGeometryKHR** ppGeometries_backing = nullptr;
	// -- Instructions --
	sptr->sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(sptr->sType == VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR);
	read_extension(reader, (VkBaseOutStructure**)&sptr->pNext);
	sptr->type = static_cast<VkAccelerationStructureTypeKHR>(reader.read_uint32_t());
	sptr->flags = static_cast<VkBuildAccelerationStructureFlagsKHR>(reader.read_uint32_t());
	sptr->mode = static_cast<VkBuildAccelerationStructureModeKHR>(reader.read_uint32_t());
	accelerationstructurekhr_index = reader.read_handle();
	sptr->srcAccelerationStructure = index_to_VkAccelerationStructureKHR.at(accelerationstructurekhr_index);
	accelerationstructurekhr_index = reader.read_handle();
	sptr->dstAccelerationStructure = index_to_VkAccelerationStructureKHR.at(accelerationstructurekhr_index);
	geometryCount = reader.read_uint32_t(); // indirect read because it is a count
	sptr->geometryCount = geometryCount;
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load pGeometries
	if (tmp_uuint8t)
	{
		pGeometries_backing = reader.pool.allocate<VkAccelerationStructureGeometryKHR>(geometryCount);
		memset(pGeometries_backing, 0, geometryCount * sizeof(VkAccelerationStructureGeometryKHR));
		sptr->pGeometries = pGeometries_backing;
		for (unsigned sidx = 0; sidx < sptr->geometryCount; sidx++) // varname=pGeometries_backing
		{
			read_VkAccelerationStructureGeometryKHR(reader, &pGeometries_backing[sidx]);
		}
	}
	tmp_uuint8t = reader.read_uint8_t(); // whether we should load ppGeometries
	if (tmp_uuint8t)
	{
		ppGeometries_backing = reader.pool.allocate<VkAccelerationStructureGeometryKHR*>(geometryCount);
		memset(ppGeometries_backing, 0, geometryCount * sizeof(VkAccelerationStructureGeometryKHR*));
		sptr->ppGeometries = ppGeometries_backing;
		for (unsigned sidx = 0; sidx < sptr->geometryCount; sidx++) // varname=ppGeometries_backing
		{
			ppGeometries_backing[sidx] = reader.pool.allocate<VkAccelerationStructureGeometryKHR>(1);
			read_VkAccelerationStructureGeometryKHR(reader, ppGeometries_backing[sidx]);
		}
	}

	const uint64_t stored_address = reader.read_uint64_t();
	sptr->scratchData.deviceAddress = reader.parent->device_address_remapping.translate_address(stored_address);
	ILOG("Changing device address from %lu to %lu", (unsigned long)stored_address, (unsigned long)sptr->scratchData.deviceAddress);
}

void retrace_vkGetSwapchainImagesKHR(lava_file_reader& reader)
{
	VkResult result;
	const uint32_t device_index = reader.read_handle();
	const uint32_t swapchain_index = reader.read_handle();
	VkDevice device = index_to_VkDevice.at(device_index);
	const uint8_t do_call = reader.read_uint8_t();
	const VkResult stored_retval = (VkResult)reader.read_uint32_t();
	const uint32_t stored_image_count = reader.read_uint32_t();
	if (!do_call) return;

	VkSwapchainKHR swapchain = index_to_VkSwapchainKHR.at(swapchain_index);
	trackedswapchain_replay& data = VkSwapchainKHR_index.at(swapchain_index);

	if (!is_noscreen() && reader.run)
	{
		uint32_t pSwapchainImageCount;
		result = wrap_vkGetSwapchainImagesKHR(device, swapchain, &pSwapchainImageCount, nullptr);
		if (!is_virtualswapchain()) assert(stored_image_count == pSwapchainImageCount);
		data.pSwapchainImages.resize(pSwapchainImageCount);
		result = wrap_vkGetSwapchainImagesKHR(device, swapchain, &pSwapchainImageCount, data.pSwapchainImages.data());
		assert(result == VK_SUCCESS);
		(void)result;
	}

	if (!data.initialized && is_virtualswapchain() && reader.run) // create virtual swapchain
	{
		// Make virtual images
		VkImageCreateInfo pinfo = {};
		pinfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
		pinfo.flags = (data.info.flags & VK_SWAPCHAIN_CREATE_MUTABLE_FORMAT_BIT_KHR);
		pinfo.imageType = VK_IMAGE_TYPE_2D;
		pinfo.extent.height = data.info.imageExtent.height;
		pinfo.extent.width = data.info.imageExtent.width;
		pinfo.extent.depth = 1;
		pinfo.format = data.info.imageFormat;
		pinfo.mipLevels = 1;
		pinfo.arrayLayers = data.info.imageArrayLayers;
		pinfo.samples = VK_SAMPLE_COUNT_1_BIT;
		pinfo.tiling = VK_IMAGE_TILING_OPTIMAL;
		pinfo.usage = data.info.imageUsage | VK_IMAGE_USAGE_TRANSFER_SRC_BIT;
		pinfo.sharingMode = data.info.imageSharingMode;
		assert(pinfo.sharingMode == VK_SHARING_MODE_EXCLUSIVE); // TBD
		pinfo.queueFamilyIndexCount = selected_queue_family_index;
		pinfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
		data.virtual_images.resize(stored_image_count);
		for (unsigned i = 0; i < stored_image_count; i++)
		{
			result = wrap_vkCreateImage(device, &pinfo, nullptr, &data.virtual_images[i]);
			assert(result == VK_SUCCESS);
		}
		suballoc_virtualswap_images(device, data.virtual_images);

		if (is_noscreen())
		{
			data.pSwapchainImages.resize(stored_image_count);
			for (uint32_t i = 0; i < stored_image_count; i++) data.pSwapchainImages[i] = data.virtual_images[i];
		}

		// Setup image region for later copy
		data.virtual_image_copy_region.srcSubresource = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 0, 1 };
		data.virtual_image_copy_region.srcOffset = { 0, 0, 0 };
		data.virtual_image_copy_region.dstSubresource = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 0, 1 };
		data.virtual_image_copy_region.dstOffset = { 0, 0, 0 };
		data.virtual_image_copy_region.extent.width = data.info.imageExtent.width;
		data.virtual_image_copy_region.extent.height = data.info.imageExtent.height;
		data.virtual_image_copy_region.extent.depth = 1;
		// Make fences
		data.inflight.resize(stored_image_count, false);
		VkFenceCreateInfo fenceinfo = { VK_STRUCTURE_TYPE_FENCE_CREATE_INFO, nullptr, 0 };
		data.virtual_fences.resize(stored_image_count);
		for (unsigned i = 0; i < stored_image_count; i++)
		{
			result = wrap_vkCreateFence(device, &fenceinfo, nullptr, &data.virtual_fences[i]);
			assert(result == VK_SUCCESS);
		}
		// Make shared semaphore
		VkSemaphoreCreateInfo semainfo = { VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO, nullptr, 0 };
		result = wrap_vkCreateSemaphore(device, &semainfo, nullptr, &data.virtual_semaphore);
		assert(result == VK_SUCCESS);
		// Make virtual image commandbuffers
		VkCommandPoolCreateInfo command_pool_create_info = {};
		command_pool_create_info.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
		command_pool_create_info.flags = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT;
		command_pool_create_info.queueFamilyIndex = selected_queue_family_index;
		result = wrap_vkCreateCommandPool(device, &command_pool_create_info, NULL, &data.virtual_cmdpool);
		assert(result == VK_SUCCESS);
		assert(data.virtual_cmdpool != VK_NULL_HANDLE);
		VkCommandBufferAllocateInfo command_buffer_allocate_info = {};
		command_buffer_allocate_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		command_buffer_allocate_info.commandPool = data.virtual_cmdpool;
		command_buffer_allocate_info.commandBufferCount = stored_image_count;
		data.virtual_cmdbuffers.resize(stored_image_count);
		result = wrap_vkAllocateCommandBuffers(device, &command_buffer_allocate_info, data.virtual_cmdbuffers.data());
		assert(result == VK_SUCCESS);
	}

	for (uint32_t i = 0; i < stored_image_count; i++)
	{
		const uint32_t remap_index = reader.read_handle();
		if (!reader.run) index_to_VkImage.set(remap_index, fake_handle<VkImage>(remap_index));
		else if (!is_virtualswapchain()) index_to_VkImage.set(remap_index, data.pSwapchainImages[i]);
		else index_to_VkImage.set(remap_index, data.virtual_images[i]);
		DLOG("Image index %u is swapchain image index %u", remap_index, i);
	}
	data.initialized = true; // in case this function is called more than once
}

void retrace_vkCreateAndroidSurfaceKHR(lava_file_reader& reader)
{
	VkInstance instance = index_to_VkInstance.at(reader.read_handle());
	const uint32_t sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(sType == VK_STRUCTURE_TYPE_ANDROID_SURFACE_CREATE_INFO_KHR);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t flags = reader.read_uint32_t();
	(void)flags; // nothing here yet
	const int32_t x = reader.read_int32_t();
	const int32_t y = reader.read_int32_t();
	const int32_t width = reader.read_int32_t();
	const int32_t height = reader.read_int32_t();
	DLOG("window originally from android width=%d height=%d", width, height);
	const int32_t stride = reader.read_int32_t();
	(void)stride; // just here FYI
	const int32_t format = reader.read_int32_t();
	(void)format; // nothing here yet
	// Execute
	const uint32_t retval = reader.read_uint32_t();
	(void)retval;
	const uint32_t surface_index = reader.read_handle();
	VkSurfaceKHR pSurface = VK_NULL_HANDLE;
	if (!is_noscreen() && reader.run) window_create(instance, surface_index, x, y, width, height);
	else pSurface = fake_handle<VkSurfaceKHR>(surface_index);
	// Post
	index_to_VkSurfaceKHR.set(surface_index, pSurface);
}

void retrace_vkCreateXcbSurfaceKHR(lava_file_reader& reader)
{
	VkInstance instance = index_to_VkInstance.at(reader.read_handle());
	const uint32_t sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(sType == VK_STRUCTURE_TYPE_XCB_SURFACE_CREATE_INFO_KHR);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t flags = reader.read_uint32_t(); // VkXcbSurfaceCreateFlagsKHR
	(void)flags; // nothing here yet
	const int32_t x = reader.read_int32_t();
	const int32_t y = reader.read_int32_t();
	const int32_t width = reader.read_int32_t();
	const int32_t height = reader.read_int32_t();
	DLOG("window originally from xcb width=%d height=%d", width, height);
	const int32_t border_width = reader.read_int32_t();
	(void)border_width; // ignore
	const int32_t depth = reader.read_int32_t();
	(void)depth; // ignore
	// Execute
	const uint32_t retval = reader.read_uint32_t();
	(void)retval;
	const uint32_t surface_index = reader.read_handle();
	VkSurfaceKHR pSurface = VK_NULL_HANDLE;
	if (!is_noscreen() && reader.run)
	{
		pSurface = window_create(instance, surface_index, x, y, width, height);
	}
	else pSurface = fake_handle<VkSurfaceKHR>(surface_index);
	// Post
	index_to_VkSurfaceKHR.set(surface_index, pSurface);
}

void retrace_vkCreateXlibSurfaceKHR(lava_file_reader& reader)
{
	VkInstance instance = index_to_VkInstance.at(reader.read_handle());
	const uint32_t sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(sType == VK_STRUCTURE_TYPE_XLIB_SURFACE_CREATE_INFO_KHR);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t flags = reader.read_uint32_t();
	(void)flags; // nothing here yet
	const int32_t x = reader.read_int32_t();
	const int32_t y = reader.read_int32_t();
	const int32_t width = reader.read_int32_t();
	const int32_t height = reader.read_int32_t();
	DLOG("window originally from xlib width=%d height=%d", width, height);
	const int32_t border_width = reader.read_int32_t();
	(void)border_width; // ignore
	const int32_t depth = reader.read_int32_t();
	(void)depth; // ignore
	// Execute
	const uint32_t retval = reader.read_uint32_t();
	(void)retval;
	const uint32_t surface_index = reader.read_handle();
	VkSurfaceKHR pSurface = VK_NULL_HANDLE;
	if (!is_noscreen() && reader.run) pSurface = window_create(instance, surface_index, x, y, width, height);
	else pSurface = fake_handle<VkSurfaceKHR>(surface_index);
	// Post
	index_to_VkSurfaceKHR.set(surface_index, pSurface);
}

void retrace_vkCreateWaylandSurfaceKHR(lava_file_reader& reader)
{
	VkInstance instance = index_to_VkInstance.at(reader.read_handle());
	const uint32_t sType = reader.read_uint32_t();
	assert(sType == VK_STRUCTURE_TYPE_WAYLAND_SURFACE_CREATE_INFO_KHR);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t flags = reader.read_uint32_t();
	(void)flags; // nothing
	// Execute
	const int32_t x = reader.read_int32_t();
	const int32_t y = reader.read_int32_t();
	const int32_t width = reader.read_int32_t();
	const int32_t height = reader.read_int32_t();
	DLOG("window originally from wayland width=%d height=%d", width, height);
	(void)reader.read_int32_t(); // reserved
	const uint32_t retval = reader.read_uint32_t();
	(void)retval;
	const uint32_t surface_index = reader.read_handle();
	VkSurfaceKHR pSurface = VK_NULL_HANDLE;
	if (!is_noscreen() && reader.run) pSurface = window_create(instance, surface_index, x, y, width, height);
	else pSurface = fake_handle<VkSurfaceKHR>(surface_index);
	// Post
	index_to_VkSurfaceKHR.set(surface_index, pSurface);
}

void retrace_vkCreateHeadlessSurfaceEXT(lava_file_reader& reader)
{
	VkInstance instance = index_to_VkInstance.at(reader.read_handle());
	const uint32_t sType = reader.read_uint32_t();
	assert(sType == VK_STRUCTURE_TYPE_HEADLESS_SURFACE_CREATE_INFO_EXT);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t flags = reader.read_uint32_t();
	(void)flags; // nothing
	// Execute
	(void)reader.read_int32_t();
	(void)reader.read_int32_t();
	(void)reader.read_int32_t();
	(void)reader.read_int32_t();
	(void)reader.read_int32_t();
	(void)reader.read_int32_t();
	// We must read these values from JSON, since they are only set when the
	// first frame is drawn, from the swapchain imageExtent. Assuming only a
	// single swapchain and surface for now.
	trackedswapchain_replay& t = VkSwapchainKHR_index.at(0);
	const int32_t x = 0;
	const int32_t y = 0;
	const int32_t width = t.info.imageExtent.width;
	const int32_t height = t.info.imageExtent.height;
	DLOG("window originally from headless width=%d height=%d (values taken from json)", width, height);
	const uint32_t retval = reader.read_uint32_t();
	(void)retval;
	const uint32_t surface_index = reader.read_handle();
	VkSurfaceKHR pSurface = VK_NULL_HANDLE;
	if (!is_noscreen() && reader.run) pSurface = window_create(instance, surface_index, x, y, width, height);
	else pSurface = fake_handle<VkSurfaceKHR>(surface_index);
	// Post
	index_to_VkSurfaceKHR.set(surface_index, pSurface);
}

void retrace_vkCreateWin32SurfaceKHR(lava_file_reader& reader)
{
	assert(false);
}

void retrace_vkCreateDirectFBSurfaceEXT(lava_file_reader& reader)
{
	assert(false);
}

void retrace_vkCreateMetalSurfaceEXT(lava_file_reader& reader)
{
	assert(false);
}

void retrace_vkGetDeviceQueue2(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	VkDevice device = index_to_VkDevice.at(device_index);
	VkDeviceQueueInfo2 info_real = {};
	read_VkDeviceQueueInfo2(reader, &info_real);
	bool virtual_family = false;
	uint32_t realIndex = info_real.queueIndex;
	uint32_t realFamily = info_real.queueFamilyIndex;
	VkQueue queue = fake_handle<VkQueue>((info_real.queueFamilyIndex << 16) + info_real.queueIndex);
	if (info_real.queueFamilyIndex == LAVATUBE_VIRTUAL_QUEUE && reader.run)
	{
		virtual_family = true;
		info_real.queueFamilyIndex = selected_queue_family_index;
		const VkQueueFamilyProperties& props = device_VkQueueFamilyProperties.at(info_real.queueFamilyIndex);
		if (info_real.queueIndex >= props.queueCount) // we don't have enough queues
		{
			info_real.queueIndex = 0; // map to first queue
		}
	}
	if (reader.run)
	{
		wrap_vkGetDeviceQueue2(device, &info_real, &queue);
		assert(queue != VK_NULL_HANDLE);
	}
	const uint32_t stored_queue_index = reader.read_handle();
	if (!index_to_VkQueue.contains(stored_queue_index))
	{
		index_to_VkQueue.set(stored_queue_index, queue);
		auto& queue_data = VkQueue_index.at(stored_queue_index);
		queue_data.device = device;
		queue_data.queueIndex = info_real.queueIndex;
		queue_data.queueFamily = info_real.queueFamilyIndex;
		queue_data.realIndex = realIndex;
		queue_data.realFamily = realFamily;
		queue_data.realQueue = queue;
		if (reader.run)
		{
			const VkQueueFamilyProperties& props = device_VkQueueFamilyProperties.at(info_real.queueFamilyIndex);
			queue_data.queueFlags = props.queueFlags;
		}
		queue_data.physicalDevice = VkDevice_index.at(device_index).physicalDevice;
	}
}

void retrace_vkGetDeviceQueue(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	VkDevice device = index_to_VkDevice.at(device_index);
	uint32_t queueFamilyIndex = reader.read_uint32_t();
	uint32_t queueIndex = reader.read_uint32_t();
	VkQueue queue = fake_handle<VkQueue>((queueFamilyIndex << 16) + queueIndex);
	bool virtual_family = false;
	uint32_t realIndex = queueIndex;
	uint32_t realFamily = queueFamilyIndex;
	if (queueFamilyIndex == LAVATUBE_VIRTUAL_QUEUE && reader.run)
	{
		virtual_family = true;
		queueFamilyIndex = selected_queue_family_index;
		const VkQueueFamilyProperties& props = device_VkQueueFamilyProperties.at(queueFamilyIndex);
		if (queueIndex >= props.queueCount) // we don't have enough queues
		{
			queueIndex = 0; // map to first queue
		}
	}
	if (reader.run)
	{
		wrap_vkGetDeviceQueue(device, queueFamilyIndex, queueIndex, &queue);
		assert(queue != VK_NULL_HANDLE);
	}
	const uint32_t stored_queue_index = reader.read_handle();
	if (!index_to_VkQueue.contains(stored_queue_index))
	{
		index_to_VkQueue.set(stored_queue_index, queue);
		auto& queue_data = VkQueue_index.at(stored_queue_index);
		queue_data.device = device;
		queue_data.queueIndex = queueIndex;
		queue_data.queueFamily = queueFamilyIndex;
		queue_data.realIndex = realIndex;
		queue_data.realFamily = realFamily;
		queue_data.realQueue = queue;
		if (reader.run)
		{
			const VkQueueFamilyProperties& props = device_VkQueueFamilyProperties.at(queueFamilyIndex);
			queue_data.queueFlags = props.queueFlags;
		}
		queue_data.physicalDevice = VkDevice_index.at(device_index).physicalDevice;
	}
}

void read_hw_buffer(lava_file_reader& reader)
{
	reader.read_uint32_t(); // hw_buffer_description.width
	reader.read_uint32_t(); // hw_buffer_description.height
	reader.read_uint32_t(); // hw_buffer_description.layers
	reader.read_uint32_t(); // hw_buffer_description.format
	reader.read_uint64_t(); // hw_buffer_description.usage
	reader.read_uint32_t(); // hw_buffer_description.stride
	reader.read_uint32_t(); // hw_buffer_description.rfu0
	reader.read_uint64_t(); // hw_buffer_description.rfu1
	reader.read_uint32_t(); // bpp
}

void retrace_vkGetAndroidHardwareBufferPropertiesANDROID(lava_file_reader& reader)
{
	// Load
	const uint32_t device_index = reader.read_handle();

	// Unused metadata
	read_hw_buffer(reader);

	// Execute
	VkResult retval = VK_SUCCESS;
	VkResult stored_retval = static_cast<VkResult>(reader.read_uint32_t());
	check_retval(stored_retval, retval);
	// Post
	// single length struct follows
	VkStructureType pProperties_sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(pProperties_sType == VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_PROPERTIES_ANDROID);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint64_t pProperties_allocationSize = reader.read_uint64_t();
	const uint32_t memoryTypeBits = reader.read_uint32_t();
}

// TBD - this needs fixing
void retrace_vkGetMemoryAndroidHardwareBufferANDROID(lava_file_reader& reader)
{
	const uint32_t device_index = reader.read_handle();
	VkStructureType sType = static_cast<VkStructureType>(reader.read_uint32_t());
	assert(sType == VK_STRUCTURE_TYPE_MEMORY_GET_ANDROID_HARDWARE_BUFFER_INFO_ANDROID);

	VkBaseOutStructure* pNext = nullptr;
	read_extension(reader, (VkBaseOutStructure**)&pNext);

	const uint32_t memory_index = reader.read_handle();
	(void)memory_index;

	// Execute
	VkResult retval = VK_SUCCESS;
	VkResult stored_retval = static_cast<VkResult>(reader.read_uint32_t());
	check_retval(stored_retval, retval);

	// Unused metadata
	read_hw_buffer(reader);
}

void retrace_vkEnumerateInstanceLayerProperties(lava_file_reader& reader)
{
	// Declarations
	std::vector<VkLayerProperties> pProperties;
	uint32_t pPropertyCount = 0;
	// Load
	uint8_t do_call = reader.read_uint8_t();
	// Execute
	if (do_call == 1 && reader.run)
	{
		VkResult retval = wrap_vkEnumerateInstanceLayerProperties(&pPropertyCount, nullptr);
		assert(retval == VK_SUCCESS);
		pProperties.resize(pPropertyCount);
		retval = wrap_vkEnumerateInstanceLayerProperties(&pPropertyCount, pProperties.data());
		assert(retval == VK_SUCCESS);
		(void)retval; // ignore return value
	}
	(void)reader.read_uint32_t(); // ignore stored return value
	// Post
}

void retrace_vkEnumerateInstanceExtensionProperties(lava_file_reader& reader)
{
	// Declarations
	const char* pLayerName = nullptr;
	std::vector<VkExtensionProperties> pProperties;
	uint32_t pPropertyCount = 0;
	// Load
	pLayerName = reader.read_string();
	uint8_t do_call = reader.read_uint8_t();
	// Execute
	if (do_call == 1 && reader.run)
	{
		VkResult retval = wrap_vkEnumerateInstanceExtensionProperties(pLayerName, &pPropertyCount, nullptr);
		assert(retval == VK_SUCCESS);
		pProperties.resize(pPropertyCount);
		retval = wrap_vkEnumerateInstanceExtensionProperties(pLayerName, &pPropertyCount, pProperties.data());
		assert(retval == VK_SUCCESS);
		(void)retval; // ignore return value
	}
	(void)reader.read_uint32_t(); // ignore stored return value
	// Post
}

void retrace_vkEnumerateDeviceLayerProperties(lava_file_reader& reader)
{
	// Declarations
	std::vector<VkLayerProperties> pProperties;
	uint32_t pPropertyCount = 0;
	// Load
	const uint8_t initialized = reader.read_uint8_t();
	uint32_t physicalDevice_index;
	if (initialized)
	{
		physicalDevice_index = reader.read_handle();
	}

	const uint8_t do_call = reader.read_uint8_t();
	// Execute
	if (do_call == 1 && reader.run)
	{
		VkResult retval = wrap_vkEnumerateDeviceLayerProperties(selected_physical_device, &pPropertyCount, nullptr);
		assert(retval == VK_SUCCESS);
		pProperties.resize(pPropertyCount);
		retval = wrap_vkEnumerateDeviceLayerProperties(selected_physical_device, &pPropertyCount, pProperties.data());
		assert(retval == VK_SUCCESS);
		(void)retval; // ignore return value
	}
	(void)reader.read_uint32_t(); // ignore stored return value
	// Post
}

void retrace_vkEnumerateDeviceExtensionProperties(lava_file_reader& reader)
{
	// Declarations
	const char* pLayerName = nullptr;
	std::vector<VkExtensionProperties> pProperties;
	uint32_t pPropertyCount = 0;
	// Load
	const uint8_t initialized = reader.read_uint8_t();
	uint32_t physicalDevice_index;
	if (initialized)
	{
		physicalDevice_index = reader.read_handle();
	}
	pLayerName = reader.read_string();
	const uint8_t do_call = reader.read_uint8_t();
	// Execute
	if (do_call == 1 && reader.run)
	{
		VkResult retval = wrap_vkEnumerateDeviceExtensionProperties(selected_physical_device, pLayerName, &pPropertyCount, nullptr);
		assert(retval == VK_SUCCESS);
		pProperties.resize(pPropertyCount);
		retval = wrap_vkEnumerateDeviceExtensionProperties(selected_physical_device, pLayerName, &pPropertyCount, pProperties.data());
		assert(retval == VK_SUCCESS);
		(void)retval; // ignore return value
	}
	(void)reader.read_uint32_t(); // ignore stored return value
	// Post
}

void retrace_vkGetPhysicalDeviceXlibPresentationSupportKHR(lava_file_reader& reader)
{
	uint32_t physicaldevice_index = reader.read_handle();
	uint32_t queueFamilyIndex = reader.read_uint32_t();
	// this function is ignored on replay
	(void)reader.read_uint32_t(); // also ignore result return value
}


// --- JSON helpers ---

static void trackable_helper(trackable& t, const Json::Value& v)
{
	t.index = v["index"].asUInt();
	t.creation.frame = v["frame_created"].asUInt();
	if (v.isMember("call_created")) t.creation.call = v["call_created"].asUInt();
	if (v.isMember("thread_created")) t.creation.thread = v["thread_created"].asUInt();
	if (v.isMember("api_created")) t.creation.call_id = v["api_created"].asUInt();
	if (v.isMember("frame_destroyed")) // check for legacy value of -1
	{
		if (v["frame_destroyed"].type() == Json::intValue && v["frame_destroyed"].asInt() == -1) { t.destroyed.frame = UINT32_MAX; }
		else t.destroyed.frame = v["frame_destroyed"].asUInt();
	}
	if (v.isMember("call_destroyed")) t.destroyed.call = v["call_destroyed"].asUInt();
	if (v.isMember("thread_destroyed")) t.destroyed.thread = v["thread_destroyed"].asUInt();
	if (v.isMember("api_destroyed")) t.destroyed.call_id = v["api_destroyed"].asUInt();
	if (v.isMember("name")) t.name = v["name"].asString();
}

static trackable trackable_json(const Json::Value& v)
{
	trackable t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackedfence trackedfence_json(const Json::Value& v)
{
	trackedfence t;
	trackable_helper(t, v);
	t.flags = v["flags"].asInt();
	t.enter_initialized();
	return t;
}

static trackedpipeline trackedpipeline_json(const Json::Value& v)
{
	trackedpipeline t;
	trackable_helper(t, v);
	t.flags = v["flags"].asUInt();
	t.type = (VkPipelineBindPoint)v["type"].asUInt();
	t.enter_initialized();
	return t;
}

static trackedaccelerationstructure trackedaccelerationstructure_json(const Json::Value& v)
{
	trackedaccelerationstructure t;
	trackable_helper(t, v);
	t.size = (VkDeviceSize)v["size"].asUInt64();
	t.offset = (VkDeviceSize)v["offset"].asUInt64();
	t.buffer_index = v["buffer_index"].asUInt();
	t.enter_initialized();
	t.object_type = VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_KHR;
	return t;
}

static trackedbuffer trackedbuffer_json(const Json::Value& v)
{
	trackedbuffer t;
	trackable_helper(t, v);
	t.size = (VkDeviceSize)v["size"].asUInt64();
	t.flags = (VkBufferCreateFlags)v["flags"].asUInt();
	t.sharingMode = (VkSharingMode)v["sharingMode"].asUInt();
	t.usage = (VkBufferUsageFlags)v["usage"].asUInt();
	t.req.size = v["req_size"].asUInt64();
	t.req.alignment = v["req_alignment"].asUInt();
	t.req.memoryTypeBits = 0;
	t.object_type = VK_OBJECT_TYPE_BUFFER;
	t.enter_initialized();
	return t;
}

static trackedimage trackedimage_json(const Json::Value& v)
{
	trackedimage t;
	trackable_helper(t, v);
	t.tiling = (VkImageTiling)v["tiling"].asUInt();
	t.flags = (VkImageCreateFlags)v["flags"].asUInt();
	t.sharingMode = (VkSharingMode)v["sharingMode"].asUInt();
	t.usage = (VkImageUsageFlags)v["usage"].asUInt();
	t.imageType = (VkImageType)v["imageType"].asUInt();
	t.req.size = v["req_size"].asUInt64();
	t.req.alignment = v["req_alignment"].asUInt();
	t.req.memoryTypeBits = 0;
	t.initialLayout = (VkImageLayout)(v.get("initialLayout", 0).asUInt());
	t.currentLayout = t.initialLayout;
	t.samples = (VkSampleCountFlagBits)(v.get("samples", 0).asUInt());
	t.mipLevels = (unsigned)v.get("mipLevels", 0).asUInt();
	t.arrayLayers = (unsigned)v.get("arrayLevels", 0).asUInt();
	t.format = (VkFormat)v.get("format", VK_FORMAT_MAX_ENUM).asUInt();
	if (v.isMember("extent"))
	{
		t.extent.width = v["extent"][0].asUInt();
		t.extent.height = v["extent"][1].asUInt();
		t.extent.depth = v["extent"][2].asUInt();
	}
	t.object_type = VK_OBJECT_TYPE_IMAGE;
	t.enter_initialized();
	return t;
}

static trackedswapchain_replay trackedswapchain_replay_json(const Json::Value& v)
{
	trackedswapchain_replay t;
	trackable_helper(t, v);
	t.info.imageFormat = (VkFormat)v["imageFormat"].asUInt();
	t.info.imageUsage = (VkImageUsageFlags)v["imageUsage"].asUInt();
	t.info.imageExtent.width = v["width"].asUInt();
	t.info.imageExtent.height = v["height"].asUInt();
	t.info.imageSharingMode = (VkSharingMode)v["imageSharingMode"].asUInt();
	t.enter_initialized();
	return t;
}

static trackedcmdbuffer trackedcmdbuffer_json(const Json::Value& v)
{
	trackedcmdbuffer t;
	trackable_helper(t, v);
	t.pool_index = v["pool"].asUInt();
	t.enter_initialized();
	return t;
}

static trackedimageview trackedimageview_json(const Json::Value& v)
{
	trackedimageview t;
	trackable_helper(t, v);
	t.image_index = v["image"].asUInt();
	t.enter_initialized();
	return t;
}

static trackedbufferview trackedbufferview_json(const Json::Value& v)
{
	trackedbufferview t;
	trackable_helper(t, v);
	t.buffer_index = v["buffer"].asUInt();
	t.enter_initialized();
	return t;
}

static trackeddescriptorset trackeddescriptorset_json(const Json::Value& v)
{
	trackeddescriptorset t;
	trackable_helper(t, v);
	t.pool_index = v["pool"].asUInt();
	t.enter_initialized();
	return t;
}

static trackedqueue trackedqueue_json(const Json::Value& v)
{
	trackedqueue t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackeddevice trackeddevice_json(const Json::Value& v)
{
	trackeddevice t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackedphysicaldevice trackedphysicaldevice_json(const Json::Value& v)
{
	trackedphysicaldevice t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackedframebuffer trackedframebuffer_json(const Json::Value& v)
{
	trackedframebuffer t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackedshadermodule trackedshadermodule_json(const Json::Value& v)
{
	trackedshadermodule t;
	trackable_helper(t, v);
	if (v.isMember("size")) t.name = v["size"].asInt();
	if (v.isMember("enables_device_address")) t.enables_device_address = v["enables_device_address"].asBool();
	t.enter_initialized();
	return t;
}

static trackedrenderpass trackedrenderpass_json(const Json::Value& v)
{
	trackedrenderpass t;
	trackable_helper(t, v);
	t.enter_initialized();
	return t;
}

static trackedpipelinelayout trackedpipelinelayout_json(const Json::Value& v)
{
	trackedpipelinelayout t;
	trackable_helper(t, v);
	if (v.isMember("push_constant_space_used")) t.push_constant_space_used = v["push_constant_space_used"].asUInt();
	t.enter_initialized();
	return t;
}


// --- read helpers : legacy code ---

void image_update(lava_file_reader& reader, uint32_t device_index, uint32_t image_index)
{
	suballoc_location loc = suballoc_find_image_memory(image_index);
	DLOG2("image update idx=%u flush=%s init=%s size=%lu", image_index, loc.needs_flush ? "yes" : "no", loc.needs_init ? "yes" : "no", (unsigned long)loc.size);
	VkDevice device = index_to_VkDevice.at(device_index);
	char* ptr = mem_map(reader, device, loc);
	int32_t changed = reader.read_patch(ptr, loc.size);
	mem_unmap(reader, device, loc, nullptr, ptr);
}

void buffer_update(lava_file_reader& reader, uint32_t device_index, uint32_t buffer_index)
{
	suballoc_location loc = suballoc_find_buffer_memory(buffer_index);
	DLOG2("buffer update idx=%u flush=%s init=%s size=%lu", buffer_index, loc.needs_flush ? "yes" : "no", loc.needs_init ? "yes" : "no", (unsigned long)loc.size);
	VkDevice device = index_to_VkDevice.at(device_index);
	char* ptr = mem_map(reader, device, loc);
	int32_t changed = 0;
	if (!reader.parent->remap) reader.read_patch(ptr, loc.size);
	else reader.read_patch_remapping(ptr, loc.size, VkBuffer_index.at(buffer_index));
	mem_unmap(reader, device, loc, nullptr, ptr);
}

// -- terminate everything cleanly

template<typename T, typename U, typename V>
void terminate(T vec, U owner, V destroyer)
{
	VkAllocationCallbacks allocator = {};
	VkAllocationCallbacks* pAllocator = &allocator;
	allocators_set(pAllocator);
	for (unsigned i = 0; i < vec.size(); i++)
	{
		if (vec.contains(i)) destroyer(owner, vec.at(i), pAllocator);
	}
}

void terminate_all(lava_file_reader& reader, VkDevice stored_device)
{
	for (unsigned i = 0; i < index_to_VkCommandPool.size(); i++)
	{
		VkCommandPool pool = index_to_VkCommandPool.at(i);
		wrap_vkResetCommandPool(stored_device, pool, VK_COMMAND_POOL_RESET_RELEASE_RESOURCES_BIT);
	}
	terminate(index_to_VkDebugUtilsMessengerEXT, stored_instance, wrap_vkDestroyDebugUtilsMessengerEXT);
	terminate(index_to_VkValidationCacheEXT, stored_device, wrap_vkDestroyValidationCacheEXT);
	terminate(index_to_VkDebugReportCallbackEXT, stored_instance, wrap_vkDestroyDebugReportCallbackEXT);
	terminate(index_to_VkSamplerYcbcrConversion, stored_device, wrap_vkDestroySamplerYcbcrConversionKHR);
	terminate(index_to_VkDescriptorUpdateTemplate, stored_device, wrap_vkDestroyDescriptorUpdateTemplateKHR);
	for (trackedswapchain_replay& t : VkSwapchainKHR_index)
	{
		replay_pre_vkDestroySwapchainKHR(reader, stored_device, index_to_VkSwapchainKHR.at(t.index), nullptr);
	}
	if (!is_noscreen()) terminate(index_to_VkSwapchainKHR, stored_device, wrap_vkDestroySwapchainKHR);
	if (!is_noscreen()) terminate(index_to_VkSurfaceKHR, stored_instance, wrap_vkDestroySurfaceKHR);
	for (uint32_t i = 0; i < index_to_VkSurfaceKHR.size() && !is_noscreen(); i++)
	{
		if (index_to_VkSurfaceKHR.contains(i)) window_destroy(stored_instance, i);
	}
	terminate(index_to_VkCommandPool, stored_device, wrap_vkDestroyCommandPool);
	terminate(index_to_VkFramebuffer, stored_device, wrap_vkDestroyFramebuffer);
	terminate(index_to_VkRenderPass, stored_device, wrap_vkDestroyRenderPass);
	terminate(index_to_VkDescriptorPool, stored_device, wrap_vkDestroyDescriptorPool);
	terminate(index_to_VkDescriptorSetLayout, stored_device, wrap_vkDestroyDescriptorSetLayout);
	terminate(index_to_VkSampler, stored_device, wrap_vkDestroySampler);
	terminate(index_to_VkPipelineLayout, stored_device, wrap_vkDestroyPipelineLayout);
	terminate(index_to_VkPipeline, stored_device, wrap_vkDestroyPipeline);
	for (auto& t : VkPipelineCache_index)
	{
		replay_pre_vkDestroyPipelineCache(reader, stored_device, index_to_VkPipelineCache.at(t.index), nullptr);
	}
	terminate(index_to_VkPipelineCache, stored_device, wrap_vkDestroyPipelineCache);
	terminate(index_to_VkShaderModule, stored_device, wrap_vkDestroyShaderModule);
	terminate(index_to_VkImageView, stored_device, wrap_vkDestroyImageView);
	for (uint32_t i = 0; i < index_to_VkImage.size(); i++) // do not attempt to delete swapchain images!
	{
		for (const trackedswapchain_replay& t : VkSwapchainKHR_index)
		{
			for (VkImage image : t.pSwapchainImages)
			{
				if (index_to_VkImage.contains(i) && index_to_VkImage.at(i) == image)
				{
					index_to_VkImage.unset(i);
				}
			}
		}
	}
	terminate(index_to_VkImage, stored_device, wrap_vkDestroyImage);
	terminate(index_to_VkBufferView, stored_device, wrap_vkDestroyBufferView);
	terminate(index_to_VkBuffer, stored_device, wrap_vkDestroyBuffer);
	terminate(index_to_VkQueryPool, stored_device, wrap_vkDestroyQueryPool);
	terminate(index_to_VkEvent, stored_device, wrap_vkDestroyEvent);
	terminate(index_to_VkSemaphore, stored_device, wrap_vkDestroySemaphore);
	terminate(index_to_VkFence, stored_device, wrap_vkDestroyFence);
	VkAllocationCallbacks allocator = {};
	VkAllocationCallbacks* pAllocator = &allocator;
	allocators_set(pAllocator);
	replay_pre_vkDestroyDevice(reader, stored_device, nullptr);
	wrap_vkDestroyDevice(stored_device, pAllocator);
	replay_pre_vkDestroyInstance(reader, stored_instance, nullptr);
	wrap_vkDestroyInstance(stored_instance, pAllocator);
}
